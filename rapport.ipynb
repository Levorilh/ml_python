{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14874ee2",
   "metadata": {},
   "source": [
    "# Rapport interactif\n",
    "\n",
    "### Sommaire\n",
    "I. Implémentation sur notre dataset\n",
    "\n",
    "II. Cas de tests\n",
    "\n",
    "### Rappel du sujet\n",
    "\n",
    "Nous essayerons de répondre à la problématique: \n",
    "- **Quel est ce monument parisien ?**\n",
    "\n",
    "À partir de notre dataset.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Nous avons utilisés une extension Chrome qui récupère entre 400 et 500 images à partir d'une recherche, puis nous avons nettoyés certaines images incohérentes. \n",
    "\n",
    "\n",
    "### Librairie\n",
    "\n",
    "Nous avons réalisé **ML**, notre propre librairie de machine learning en C++. Elle dépend de la bibliothèque **Eigen**, qui nous sert à réaliser plus facilement des calculs matriciels.\n",
    "\n",
    "### Application web\n",
    "\n",
    "Nous avons décidé de réaliser notre application web en Python en utilisant le micro-framework **Flask** ainsi que **Bootstrap** et **JQuery**\n",
    "\n",
    "### Étapes de développement\n",
    "\n",
    "1. Implémentation du perceptron\n",
    "2. Interopérabilité du perceptron\n",
    "3. Implémentation du perceptron multi-couches\n",
    "4. Interopérabilité du perceptron multi-couches\n",
    "5. Validation sur les cas de tests et correction de la librairie\n",
    "6. Rédaction de la première version du rapport pour l'étape n°2\n",
    "7. Création du site web\n",
    "8. Ajout des fonctionnalités save et load sur le percepetron\n",
    "9. Interopérabilité du save et du load sur le perceptron\n",
    "10. Ajout des fonctionnalités save et load sur le perceptron multi-couches\n",
    "11. Interopérabilité du save et du load sur le perceptron multi-couches\n",
    "12. Implémentation du Radial Basis Function Network\n",
    "13. Interopérabilité du Radial Basis Function Network\n",
    "14. Amélioration et finition du site web (*en cours*)\n",
    "15. Rédaction du rapport interactif (*en cours*)\n",
    "\n",
    "### Difficultés rencontrées\n",
    "\n",
    "- Problème d’initialisation des valeurs aléatoires, on avait des modèles tous identiques.\n",
    "- Tentative d’utiliser std::random_device pour obtenir des valeurs aléatoires plus uniformes. Cela fonctionnait mais on s’est rendus compte que rand() de stdlib suffisait pour notre besoin.\n",
    "- Confusions due au biais (on a tenté de le supprimer plusieurs fois)\n",
    "- Erreur d’allocation de mémoire entraînant des erreurs lors du passages des objets par l'interopérabilité\n",
    "- Destruction d'une instance d'un perceptron multi-couches, mal paramétré entraînant des erreurs lors de l’utilisation de l'interopérabilité.\n",
    "- Prise en main de NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdaaf91",
   "metadata": {},
   "source": [
    "# Partie 1. Implémentation sur notre dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2da79d",
   "metadata": {},
   "source": [
    "Dans cette partie, nous montrerons l'étape de pré-traitement des données (*data preprocessing*), puis nous appliquerons notre modéle linéaire ainsi que notre perceptron multi-couches à notre dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346e3e6",
   "metadata": {},
   "source": [
    "## a) Importer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fded975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ml import *\n",
    "from rbfn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff0f6a",
   "metadata": {},
   "source": [
    "Nous définissons les constantes dont nous aurons besoin, tout au long du rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfbf24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (64, 64)\n",
    "PATH = os.path.join(\"data_large/\")\n",
    "TRAIN = os.path.join(PATH, \"train\")\n",
    "classes = os.listdir(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89634d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes classes possibles sont: moulin-rouge, palais-de-l-elysee, pont-neuf, place-de-la-concorde, jardin-des-tuileries, hotel-de-ville, arc-de-triomphe, musee-d-orsay\n"
     ]
    }
   ],
   "source": [
    "print(f\"Les différentes classes possibles sont: {', '.join(classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056f005",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TO-DO** : Ajouter la data augmentation dans `import_images_and_assign_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42a03a28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_rotation(image):\n",
    "    \"\"\"\n",
    "    Random rotation of the image\n",
    "    \"\"\"\n",
    "    rand_rot = np.random.uniform(-25, 25)\n",
    "    return image.rotate(rand_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b738d2d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#def random_noise(image):\n",
    "#    \"\"\"\n",
    "#    Random noise added to the image\n",
    "#    \"\"\"\n",
    "#    s = np.std(image)\n",
    "#    return image.effect_noise(IMG_SIZE, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0e6f9a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(image):\n",
    "    \"\"\"\n",
    "    Flip the image horizontally\n",
    "    \"\"\"\n",
    "    return image.transpose(Image.FLIP_LEFT_RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a967df66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#def blur(image):\n",
    "#    \"\"\"\n",
    "#    Blur the image\n",
    "#    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0018b987",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    # \"noise\": random_noise,\n",
    "    \"rotate\": random_rotation,\n",
    "    \"flip\": horizontal_flip,\n",
    "}\n",
    "\n",
    "num_transformations_to_apply = np.random.randint(1, len(transformations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a064298a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def showImg(tensor, label, prediction):\n",
    "    \"\"\"\n",
    "    Affiche une image avec sa prediction et son label\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(tensor.reshape((IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    ax.set_title(f'Label: {classes[np.argmax(prediction)]}')\n",
    "    ax.set_xlabel(f'Prediction: {np.argmax(prediction)} / Expected output: {np.argmax(label)}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d30be46e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def import_images_and_assign_labels(folder, label, X, Y, IMG_SIZE=IMG_SIZE, data_aug=False):\n",
    "    \"\"\"\n",
    "    Convertit et redimensionne les images d'un dossier en NumPy Array.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        im = Image.open(image_path)\n",
    "        im = im.resize(IMG_SIZE)\n",
    "        if data_aug == True:\n",
    "            for i in range(num_transformations_to_apply):\n",
    "                k = np.random.choice(list(transformations))\n",
    "                transformed_img = transformations[k](im)\n",
    "            im = transformed_img\n",
    "        im = im.convert(\"RGB\")\n",
    "        im_arr = np.array(im)\n",
    "        im_arr = np.reshape(im_arr, (IMG_SIZE[0]* IMG_SIZE[1] * 3,))\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3aad12c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images par classes dans le train set:\n",
      "- moulin-rouge: 391 images.\n",
      "- palais-de-l-elysee: 441 images.\n",
      "- pont-neuf: 487 images.\n",
      "- place-de-la-concorde: 457 images.\n",
      "- jardin-des-tuileries: 393 images.\n",
      "- hotel-de-ville: 359 images.\n",
      "- arc-de-triomphe: 471 images.\n",
      "- musee-d-orsay: 418 images.\n",
      "Total : 3417 images.\n",
      "\n",
      "Nombre d'images par classes dans le valid set:\n",
      "- moulin-rouge: 129 images.\n",
      "- palais-de-l-elysee: 129 images.\n",
      "- pont-neuf: 129 images.\n",
      "- place-de-la-concorde: 129 images.\n",
      "- jardin-des-tuileries: 129 images.\n",
      "- hotel-de-ville: 129 images.\n",
      "- arc-de-triomphe: 129 images.\n",
      "- musee-d-orsay: 129 images.\n",
      "Total : 1032 images.\n",
      "\n",
      "Nombre d'images dans le test set:\n",
      "1041 images.\n"
     ]
    }
   ],
   "source": [
    "for s in [\"train\", \"valid\", \"test\"]:\n",
    "    if s == \"test\":\n",
    "        print(f\"Nombre d'images dans le {s} set:\")\n",
    "        print(f\"{len(os.listdir(os.path.join(PATH, s)))} images.\")\n",
    "    else:\n",
    "        print(f\"Nombre d'images par classes dans le {s} set:\")\n",
    "        res = 0\n",
    "        for cl in classes:\n",
    "            print(f\"- {cl}: {len(os.listdir(os.path.join(PATH, s, cl)))} images.\")\n",
    "            res+=len(os.listdir(os.path.join(PATH, s, cl)))\n",
    "        print(\"Total :\", res, \"images.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d0a78b17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def import_dataset(IMG_SIZE=IMG_SIZE, data_aug=False):\n",
    "    \"\"\"\n",
    "    Crée les datasets d'entrainement et de validation\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_valid, y_valid = [], [], [], []\n",
    "    labels = np.identity(len(os.listdir(TRAIN)))\n",
    "    for set_type in [\"train\", \"valid\"]:\n",
    "        for cl, lab in zip(classes, labels):\n",
    "            if set_type == \"train\":\n",
    "                X_set, y_set = X_train, y_train\n",
    "                import_images_and_assign_labels(\n",
    "                os.path.join(PATH, set_type, cl),\n",
    "                lab,\n",
    "                X_set,\n",
    "                y_set,\n",
    "                IMG_SIZE,\n",
    "                data_aug\n",
    "            )\n",
    "            else:\n",
    "                X_set, y_set = X_valid, y_valid\n",
    "                import_images_and_assign_labels(\n",
    "                    os.path.join(PATH, set_type, cl),\n",
    "                    lab,\n",
    "                    X_set,\n",
    "                    y_set,\n",
    "                    IMG_SIZE,\n",
    "\n",
    "                )\n",
    "\n",
    "    return (np.array(X_train) / 255.0, np.array(y_train)), \\\n",
    "           (np.array(X_valid) / 255.0, np.array(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0080101",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = import_dataset(data_aug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cefe14ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images par classes dans le train set:\n",
      "- moulin-rouge: 391 images.\n",
      "- palais-de-l-elysee: 441 images.\n",
      "- pont-neuf: 487 images.\n",
      "- place-de-la-concorde: 457 images.\n",
      "- jardin-des-tuileries: 393 images.\n",
      "- hotel-de-ville: 359 images.\n",
      "- arc-de-triomphe: 471 images.\n",
      "- musee-d-orsay: 418 images.\n",
      "Total : 3417 images.\n",
      "\n",
      "Nombre d'images par classes dans le valid set:\n",
      "- moulin-rouge: 129 images.\n",
      "- palais-de-l-elysee: 129 images.\n",
      "- pont-neuf: 129 images.\n",
      "- place-de-la-concorde: 129 images.\n",
      "- jardin-des-tuileries: 129 images.\n",
      "- hotel-de-ville: 129 images.\n",
      "- arc-de-triomphe: 129 images.\n",
      "- musee-d-orsay: 129 images.\n",
      "Total : 1032 images.\n",
      "\n",
      "Nombre d'images dans le test set:\n",
      "1041 images.\n"
     ]
    }
   ],
   "source": [
    "for s in [\"train\", \"valid\", \"test\"]:\n",
    "    if s == \"test\":\n",
    "        print(f\"Nombre d'images dans le {s} set:\")\n",
    "        print(f\"{len(os.listdir(os.path.join(PATH, s)))} images.\")\n",
    "    else:\n",
    "        print(f\"Nombre d'images par classes dans le {s} set:\")\n",
    "        res = 0\n",
    "        for cl in classes:\n",
    "            print(f\"- {cl}: {len(os.listdir(os.path.join(PATH, s, cl)))} images.\")\n",
    "            res+=len(os.listdir(os.path.join(PATH, s, cl)))\n",
    "        print(\"Total :\", res, \"images.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9efdfe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "picture_test = np.random.randint(0, len(X_valid)-1)\n",
    "print(picture_test)\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], [0, 0, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732db63",
   "metadata": {},
   "source": [
    "## b) Appliquer le modéle linéaire au dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd76fd",
   "metadata": {},
   "source": [
    "Cette section est incomplète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "507ef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0321b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = create_linear_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "20f8bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: -1.0\n"
     ]
    }
   ],
   "source": [
    "picture_test_linear = np.random.randint(0, len(X_train))\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, X_train[picture_test_linear])\n",
    "print(\"Before training:\", test_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfd3e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_linear_classification_model(p_model, input_dim, X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f724ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_after = predict_linear_model_classif(p_model, input_dim, X_train[picture_test])\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8502c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_linear_model(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69aac4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345f8b9",
   "metadata": {},
   "source": [
    "## c) Appliquer le PMC au dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46048e",
   "metadata": {},
   "source": [
    "Nous allons créer un petit modéle contenant une seule couche cachée puis nous allons l'entraîner pour voir s'il sera capable de prédire correctement une image de la Place de la Concorde, notre image test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0043ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(classes)\n",
    "picture_test = 411\n",
    "input_dim = [len(X_train[0]), 32, NUM_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ea72e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model, len_output_layer = create_mlp_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3aba8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    \"\"\"\n",
    "    Evalue notre modèle sur les données d'entrainement et de validation.\n",
    "    \"\"\"\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_train)\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, NUM_CLASSES)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    print(f\"Accuracy training: {round((true_preds / total_preds) * 100, 2)}%\")\n",
    "    \n",
    "    true_preds = 0\n",
    "    total_preds = len(X_valid)\n",
    "    for x, y in zip(X_valid, y_valid):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, NUM_CLASSES)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    print(f\"Accuracy valid: {round((true_preds / total_preds) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc63d67",
   "metadata": {},
   "source": [
    "Voyons si notre modéle non entrainé arrive à prédire correctement une image aléatoire du valid set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27645d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0.11572154, -0.9334035, 0.99346846, -0.999999, 0.9989392, 0.04288182, -0.857372, -0.08260946]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_before = predict_mlp_model_classification(p_model, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_before);\n",
    "\n",
    "print(\"Prediction:\", test_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cc1c1",
   "metadata": {},
   "source": [
    "Nous pouvons voir que notre modéle prédit correctement le monument environ 1 fois sur 8 (soit 12.5%). Nous avons 8 classes de monuments, ce qui veut dire que nos résultats sont totalement normaux, car notre modèle n'est pas encore entrainé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aab25861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training: 13.08%\n",
      "Accuracy valid: 12.98%\n"
     ]
    }
   ],
   "source": [
    "accuracy(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758dfa46",
   "metadata": {},
   "source": [
    "Entraînons désormais notre modéle. Par soucis de temps, nous allons entraîner manuellement un petit modéle de 1000 époques et puis nous chargerons un gros modéle déjà entraîné par nos soins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "657693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X_train, y_train.flatten(), epochs=1000)#, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c4966",
   "metadata": {},
   "source": [
    "Voyons si notre modéle entrainé arrive à prédire correctement une image aléatoire du valid set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a84a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [-0.9148435, 0.69988847, 0.9298743, -0.99914885, 0.9991444, 0.9793118, 0.21207371, 0.79525375]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_after = predict_mlp_model_classification(p_model, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_after);\n",
    "\n",
    "print(\"Prediction:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff50983",
   "metadata": {},
   "source": [
    "Prédiction **correcte** : Etait-ce un coup de chance ou notre modéle réussit désormais à distinguer les différents monuments ? \n",
    "\n",
    "Prédiction **incorrecte** : Notre modéle n'as pas réussi à prédire notre image test, as-t-il réellement appris quelque chose durant sa phase d'entraînement ? Notre modéle est potentiellement entrain de **sous-apprendre**.\n",
    "\n",
    "\n",
    "Pour en avoir le coeur net, voyons comment il s'en sort face à toutes les données du train et du valid set. Nous aurons un meilleur point de vue de son avancé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e01492a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training: 14.78%\n",
      "Accuracy valid: 14.24%\n"
     ]
    }
   ],
   "source": [
    "accuracy(p_model)\n",
    "destroy_mlp_model(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525a19e",
   "metadata": {},
   "source": [
    "Prédiction **correcte** : ^^ C'était un coup de chance, pas de bol. Le pourcentage est beaucoup trop faible, notre modéle prédit toujours l'équivalent d'une chance sur 8.\n",
    "\n",
    "Prédiction **incorrecte** : C'est tout à fait normal, notre modéle n'a pas était assez entraîné.\n",
    "\n",
    "Passons à la partie intéressante, nous allons charger un modéle pré-entrainé et nous allons effectuer le même test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87256f87",
   "metadata": {},
   "source": [
    "Pour commencer, nous allons devoir ré-importer une nouvelle fois les données mais avec une taille d'image différente, nous allons cette fois utiliser des images plus petites (8x8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd4fe6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5fbf3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = import_dataset(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224c454",
   "metadata": {},
   "source": [
    "Assurons-nous que les images soit à la bonne dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8fa4751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des images applatis : (192,)\n",
      "Dimensions souhaités : (192,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions des images applatis :\", X_train[0].shape)\n",
    "print(\"Dimensions souhaités :\", (IMG_SIZE[0]*IMG_SIZE[1]*3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78997173",
   "metadata": {},
   "source": [
    "Le prochain modéle que nous allons chargé à était entrainé 10 millions d'époques et ne contient aucune couche cachée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c8b99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model2 = load_mlp_model(\"models/mlp/MLP_10000000_8x8_8_t_acc-65.5_v_acc-58.04.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31049449",
   "metadata": {},
   "source": [
    "Est-ce que le modéle entrainé 10 millions d'époques sera capable de prédire notre image selectionné aléatoirement. La suite à la prochaine cellule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "hindu-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [-0.17864059, -0.009236684, -0.1145136, 0.8318115, 0.11925446, 0.108996004, 0.16947888, -0.2370879]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_load = predict_mlp_model_classification(p_model2, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_load);\n",
    "\n",
    "print(\"Prediction:\", test_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c77fb5",
   "metadata": {},
   "source": [
    "Prédiction **correcte** : FIIIOUUU ! On a pas travaillé 3 mois pour rien ;)\n",
    "\n",
    "Prédiction **incorrecte** : Voyons sur toutes les données comment notre modéle réagit. (3 mois à la poubelle )-: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "118495c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training: 65.5%\n",
      "Accuracy valid: 58.04%\n"
     ]
    }
   ],
   "source": [
    "accuracy(p_model2)\n",
    "destroy_mlp_model(p_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d331c1",
   "metadata": {},
   "source": [
    "On peut voir que notre modéle pré-entrainé à un peu plus de 1 chance sur 2 de prédire correctement le monument parisien sur des images qu'il n'a jamais vu.\n",
    "\n",
    "On aurait de meilleures prédictions si nous avons un modéle soit plus gros, soit plus entrainé. Essayons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550aecf",
   "metadata": {},
   "source": [
    "Le prochain modéle que nous allons chargé à était entrainé 15 millions d'époques et ne contient 3 couches cachées (16, 8, 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32bb00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model3 = load_mlp_model(\"models/mlp/overfit/MLP_15000000_16x16_16_8_8_8_t_acc-80.6_v_acc-57.27.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086da51",
   "metadata": {},
   "source": [
    "Est-ce que le modéle entrainé 15 millions d'époques sera capable de prédire notre image selectionné aléatoirement. La suite à la prochaine cellule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "575fe015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [-0.0024767136, 0.014698193, 0.018071294, 0.90510345, 0.021234252, 0.0041215764, 0.008198208, -0.008077058]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_p3 = predict_mlp_model_classification(p_model3, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_p3);\n",
    "\n",
    "print(\"Prediction:\", test_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd1922",
   "metadata": {},
   "source": [
    "Réponse logique, oui. Maintenant, voyons sur toutes les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f6d81dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training: 79.16%\n",
      "Accuracy valid: 62.79%\n"
     ]
    }
   ],
   "source": [
    "accuracy(p_model3)\n",
    "destroy_mlp_model(p_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005d02a",
   "metadata": {},
   "source": [
    "Aïe, notre modéle a sur-appris. :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c92ac",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba37735",
   "metadata": {},
   "source": [
    "## d) Découverte de nouveaux modéles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5316d9",
   "metadata": {},
   "source": [
    "Pour faciliter notre recherche d'architectures, nous avons décidé de créer un équivalent au **GridSearch** de Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3c7d3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779251c",
   "metadata": {},
   "source": [
    "On insére les hyperparametres que l'on souhaite essayer sur notre modéle à la prochaine cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b800da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = [0, 1, 2, 3]\n",
    "hidden_layers = [8, 16, 32]\n",
    "size_img = [(8, 8), (16, 16), (32, 32)]\n",
    "EPOCHS = [10000000, 15000000] # len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5c294429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_for_grid_search(model, len_output, X_tr, y_tr, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Evalue notre modéle sur les données d'entrainement et de validation.\n",
    "    \"\"\"\n",
    "    train_total, valid_total = len(X_train), len(X_valid)\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_tr)\n",
    "    for x, y in zip(X_tr, y_tr):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    train_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    true_preds = 0\n",
    "    total_preds = len(X_val)\n",
    "    for x, y in zip(X_val, y_val):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    valid_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    return train_acc, valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67b997",
   "metadata": {},
   "source": [
    "Notre fonction `grid_search()` a pour but de trouver le modéle qui a les meilleures résultats de prédictions et de les enregistrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1f83eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(epochs=EPOCHS, size_img=size_img, hidden_layers=hidden_layers, number_of_hidden_layers=number_of_hidden_layers):\n",
    "    \"\"\"\n",
    "    Equivalent au Grid Search de Sklearn.\n",
    "    \"\"\"\n",
    "    max_train_acc, max_val_acc = 0.0, 0.0\n",
    "\n",
    "    for ep in EPOCHS:\n",
    "        for s in size_img:\n",
    "            IMG_SIZE = s\n",
    "            (X_train, y_train), (X_valid, y_valid) = import_dataset(IMG_SIZE=IMG_SIZE)\n",
    "            input_dim = [len(X_train[0])]\n",
    "            for n, num_h in enumerate(number_of_hidden_layers):\n",
    "                h = random.choices(hidden_layers, k=num_h)\n",
    "                if h:\n",
    "                    input_dim.extend(random.choices(hidden_layers, k=num_h))\n",
    "                input_dim.append(NUM_CLASSES)\n",
    "\n",
    "                model, last_output_layer = create_mlp_model(input_dim)\n",
    "                train_classification_stochastic_gradient_backpropagation_mlp_model(model, X_train, y_train.flatten(), epochs=ep)\n",
    "\n",
    "                train_acc, valid_acc = accuracy_for_grid_search(model, last_output_layer, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "                if input_dim[1:-1] == []:\n",
    "                    filename = f\"models/mlp/MLP_{ep}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_{input_dim[-1]}_t_acc-{train_acc}_v_acc-{valid_acc}.txt\"\n",
    "                else:\n",
    "                    filename = f\"models/mlp/MLP_{ep}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_{'_'.join(map(str, input_dim[1:]))}_t_acc-{train_acc}_v_acc-{valid_acc}.txt\"\n",
    "\n",
    "                print(f\"Model parameters: epochs={ep}, img_size={IMG_SIZE}, input_dim={input_dim[1:]} -- Train acc: {train_acc}% / Valid_acc: {valid_acc}%\")\n",
    "\n",
    "                if train_acc > max_train_acc:\n",
    "                    max_train_acc = train_acc\n",
    "                    save_mlp_model(model, filename)\n",
    "                if valid_acc > max_val_acc:\n",
    "                    max_val_acc = valid_acc\n",
    "                    save_mlp_model(model, filename)\n",
    "\n",
    "                destroy_mlp_model(model)\n",
    "\n",
    "                input_dim = [len(X_train[0])]\n",
    "\n",
    "        print(f\"Max Train acc: {max_train_acc}% / Max Valid_acc: {max_val_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2e8e6",
   "metadata": {},
   "source": [
    "C'est parti, on lance la recherche d'architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80793910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787eb9b",
   "metadata": {},
   "source": [
    "Cette fonction nous a permis d'essayer toutes les possibilités des **hyperparametres** de manière automatisé, de pouvoir entraîner plusieurs **modèles** toute une nuit et d'obtenir une sorte de recap à la fin du grid search.\n",
    "\n",
    "Nous avons essayer tout un panel de taille d'image allant de 6x6 à 64x64, un nombre de couches cachées allant de 0 à 4, des nombres de noeuds par couche entre 4 et 1024 et enfin un nombre d'époques de 1000 allant jusqu'à 20M.\n",
    "\n",
    "Aujourd'hui, à notre grande surprise, nous avons découvert que pour notre problématique, les modéles sans couches cachées et avec une petite taille d'images prédisent mieux que de **grand/gros** modéles avec une grande taille d'images. \n",
    "\n",
    "En plus de leur taille, les grand modéles prennent plus de temps à s'entraîner.\n",
    "\n",
    "Nos modéles qui généralisent le mieux ont un taux de réussite d'environ 65% de précision sur des données inconnues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fa786",
   "metadata": {},
   "source": [
    "## e) Les courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7f233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_valid(model, len_output):\n",
    "    valid_total = len(X_valid)\n",
    "\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_val)\n",
    "    for x, y in zip(X_val, y_val):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    valid_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    return train_acc, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc6a633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_curves(name_model, input_dim, epochs):\n",
    "    losses, val_losses, accs, val_accs = [], [], [], []\n",
    "    if name_model.lower()==\"mlp\":\n",
    "        model, last_output_layer = create_mlp_model(input_dim)\n",
    "    elif name_model.lower()==\"perceptron\":\n",
    "        model = create_linear_model(input_dim)\n",
    "    elif name_mode.lower()==\"rbf\":\n",
    "        model = create_rbf_model()\n",
    "        \n",
    "    for ep in epochs:\n",
    "        if name_model.lower()==\"mlp\":\n",
    "            train_classification_stochastic_gradient_backpropagation_mlp_model(model, X_train, y_train.flatten(), epochs=len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e501ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mlp_curves(input_dim, epochs):\n",
    "    model, last_output_layer = create_mlp_model(input_dim)\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        train_classification_stochastic_gradient_backpropagation_mlp_model(model, X_train, y_train.flatten(), epochs=len(X_train))\n",
    "        preds = predict_mlp_model_classification(model, X_valid, input_dim[-1])\n",
    "        print(preds)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "649317d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-ca85074dc619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay_mlp_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-105-9068146fc823>\u001b[0m in \u001b[0;36mdisplay_mlp_curves\u001b[0;34m(input_dim, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_classification_stochastic_gradient_backpropagation_mlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_mlp_model_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3IABD/Projet-Annuel/ml_python/mlp.py\u001b[0m in \u001b[0;36mpredict_mlp_model_classification\u001b[0;34m(p_model, sample_input, last_layer_len)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_mlp_model_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_layer_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0msample_input_ctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msi_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_C_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# si_length = len(sample_input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/3IABD/Projet-Annuel/ml_python/mlp.py\u001b[0m in \u001b[0;36mas_C_array\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0marr_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_float\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marr_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "display_mlp_curves([len(X_train[0]), 32, NUM_CLASSES], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905665a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b5695",
   "metadata": {},
   "source": [
    "# Partie 2. Cas de tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a738c2d",
   "metadata": {},
   "source": [
    "Avant de démarrer notre recherche d'architecture viable pour nos modèles, il a fallu s'assurer que les algorithmes de notre lib étaient corrects. Pour cela, nous avons utilisé des jeux de données où les résultats sont visuellement interprétables, ou bien dont les prédictions peuvent être calculées à la main sans y passer 4heures. L'idéal était donc de travailler sur des points en 2D ou 3D, avec une quantité limitée de point. Si nos modèles permettent de classifier nos points correctement, on pourra ensuite passer à de plus gros volumes de données, dans des dimensions impossible à interpréter pour l'Humain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9579006",
   "metadata": {
    "id": "_qYwTgKqxnkl"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0702a",
   "metadata": {
    "id": "-d0zULTsyFhh"
   },
   "source": [
    "### Linear Simple :\n",
    "        Linear Model : OK\n",
    "        MLP (2, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5e15b",
   "metadata": {
    "id": "EktwRhEMxV2A"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [2.5, 4],\n",
    "      [2, 3],\n",
    "      [3, 3]\n",
    "])\n",
    "Y = np.array([\n",
    "      1,\n",
    "      -1,\n",
    "      -1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2da2c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "OpWOCJ5ZyDMY",
    "outputId": "25884536-e733-4cee-b175-79c147b7c927"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[0, 0], X[0, 1], color='blue')\n",
    "plt.scatter(X[1:3,0], X[1:3,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim = len(X[0])\n",
    "\n",
    "errors = 0\n",
    "\n",
    "for _ in range(50):\n",
    "    test_after = []\n",
    "    p_model = create_linear_model(model_dim)\n",
    "\n",
    "    train_linear_classification_model(p_model, model_dim, X, Y, alpha=0.001, epochs=10_000)\n",
    "\n",
    "    for data, expected in zip(X, Y):\n",
    "        out = predict_linear_model_classif(p_model, model_dim, data)\n",
    "        test_after.append(out)\n",
    "        if out != expected:\n",
    "            errors += 1\n",
    "    print(test_after)\n",
    "    destroy_linear_model(p_model)\n",
    "\n",
    "print(f\"errors: {errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfd32b",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, [1, 1])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y, alpha=0.001, epochs=10000)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [1, 1])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f1f02",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_linear_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 5, 0.5) for x2 in np.arange(-1, 5, 0.5)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model, input_dim,  p) for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_linear_classification_model(model, input_dim, flattened_dataset_inputs, Y, epochs=10000)\n",
    "\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model,input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim, [1, 1])\n",
    "\n",
    "print(\"Prediction after training of [1, 1], the prediction need to be equal to 1. \\nPrediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fab88",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7891e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "p_model, _= create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36986aa1",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8112c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 5, 0.5) for x2 in np.arange(-1, 5, 0.5)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model , [1, 1])\n",
    "\n",
    "print(\"Prediction after training of [1, 1], the result need to be equal to 1. Result:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f8094",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb14726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 2\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if label >= 0 else [0,1] for label in Y]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, X, expected_output)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = [[x,y] for x in range(6) for y in range(6)]\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b957dee",
   "metadata": {
    "id": "7v8KFue-zmCv"
   },
   "source": [
    "### Linear Multiple :\n",
    "        Linear Model : OK\n",
    "        MLP (2, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6d693",
   "metadata": {
    "id": "hZlnpb-qzmCw"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([np.random.random((50,2)) * 0.9 + np.array([1, 1]), np.random.random((50,2)) * 0.9 + np.array([2, 2])])\n",
    "Y = np.concatenate([np.ones((50, 1)), np.ones((50, 1)) * -1.0])\n",
    "plt.scatter(X[0:50, 0], X[0:50, 1], color='blue')\n",
    "plt.scatter(X[50:100,0], X[50:100,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c8db3",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aeeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, [1.25, 1.25])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [1.25, 1.25])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9ba94",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f62770",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_linear_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(1, 3, 0.1) for x2 in np.arange(1, 3, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "    #print(flattened_dataset_inputs)\n",
    "\n",
    "train_linear_classification_model(model, input_dim, X, Y, epochs=100000)\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model,input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [2.5, 2.5])\n",
    "\n",
    "print(\"Prediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d08eda",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "p_model, _ = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [1.25, 1.25])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1.25, 1.25])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12007487",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7077e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _= create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(1, 3, 0.1) for x2 in np.arange(1, 3, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y, epochs=100000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model , [1, 1])\n",
    "\n",
    "print(\"Prediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a0049",
   "metadata": {},
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dd911",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 20\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if label >= 0 else [0,1] for label in Y]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, X, expected_output)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = [[x/10,y/10] for x in range(51) for y in range(51)]\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1adb09",
   "metadata": {
    "id": "gZlONmsp1T_W"
   },
   "source": [
    "### XOR :\n",
    "        Linear Model    : KO\n",
    "        MLP (2, 2, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb9b8e",
   "metadata": {
    "id": "673wfC9U1T_W"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]])\n",
    "Y = np.array([1, 1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aa1f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "uA3E-h801T_Y",
    "outputId": "9fc31c6d-e44c-447b-a7c0-a3fa7b0d778e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[0:2, 0], X[0:2, 1], color='blue')\n",
    "plt.scatter(X[2:4,0], X[2:4,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd262d4",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "On isole les 4 points par 2 sorties de\n",
    "modèle linéaire, chacune entraînée par 2 valeurs d’une classe et 1 valeur de\n",
    "l’autre classe. On simule en réalité le travail d’un MLP (2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75abf7",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd76f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "Y = np.array([-1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aae1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model_top = create_linear_model(input_dim)\n",
    "model_bottom = create_linear_model(input_dim)\n",
    "\n",
    "\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 2, 0.1) for x2 in np.arange(-1, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs_top = [predict_linear_model_classif(model_top, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_bottom = [predict_linear_model_classif(model_bottom, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if top == 1 and bottom == 1 else 'red' for (top, bottom) in zip(predicted_outputs_top, predicted_outputs_bottom)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "train_linear_classification_model(model_top, input_dim, X[:-1], Y[:-1], alpha=0.01, epochs=100000)\n",
    "train_linear_classification_model(model_bottom, input_dim, X[1:], Y[1:], alpha=0.01, epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs_top = [predict_linear_model_classif(model_top, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_bottom = [predict_linear_model_classif(model_bottom, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if top == 1 and bottom == 1 else 'red' for (top, bottom) in zip(predicted_outputs_top, predicted_outputs_bottom)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "destroy_linear_model(model_top)\n",
    "destroy_linear_model(model_bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9b1aa",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0]), 1]\n",
    "\n",
    "p_model, _= create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a094c",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 2, 0.1) for x2 in np.arange(-1, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y, epochs=100000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7efe87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 4\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if label >= 0 else [0,1] for label in Y]\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, X, expected_output, naif=True)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = [[x/5,y/5] for x in range(6) for y in range(6)]\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e6c5d",
   "metadata": {
    "id": "5qxkXVo02MpM"
   },
   "source": [
    "### Cross :\n",
    "        Linear Model    : KO\n",
    "        MLP (2, 4, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487c399",
   "metadata": {
    "id": "7kkrrfnX2MpM"
   },
   "outputs": [],
   "source": [
    "X = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "Y = np.array([1 if abs(p[0]) <= 0.3 or abs(p[1]) <= 0.3 else -1 for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef933068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "zVBAE2fY2MpO",
    "outputId": "46b434a6-2fd8-492e-c080-14b0d0028968"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == 1, enumerate(X)))))[:,1], color='blue')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == -1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == -1, enumerate(X)))))[:,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5945a89",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "On génère plusieurs modèles linéaires\n",
    "qui vont découper la croix en différentes parties pour isoler 1 à 1 les blocs\n",
    "rouges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913307f",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model_vl = create_linear_model(input_dim)\n",
    "model_vr = create_linear_model(input_dim)\n",
    "model_ht = create_linear_model(input_dim)\n",
    "model_hb = create_linear_model(input_dim)\n",
    "\n",
    "\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-2, 2, 0.1) for x2 in np.arange(-2, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs_vl = [predict_linear_model_classif(model_vl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_vr = [predict_linear_model_classif(model_vr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_ht = [predict_linear_model_classif(model_ht, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_hb = [predict_linear_model_classif(model_hb, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if (vl == 1 and vr == 1) or (ht == 1 and hb == 1) else 'red' for (vl, vr, ht, hb) in zip(predicted_outputs_vl, predicted_outputs_vr, predicted_outputs_ht, predicted_outputs_hb)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ht = np.array([[x[0],x[1],n] for n,x in enumerate(X) if (x[1] > -0.3 and (x[0] > 0.3 or x[0] < -0.3) ) ])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in ht[:, 2]]\n",
    "plt.scatter(ht[:, 0], ht[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Horizontal top\")\n",
    "plt.show()\n",
    "\n",
    "vr = np.array([[x[0],x[1], int(n)] for n,x in enumerate(X) if x[0] > -0.3 and (x[1] > 0.3 or x[1] < -0.3) ])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in vr[:, 2]]\n",
    "plt.scatter(vr[:, 0], vr[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Vertical right\")\n",
    "plt.show()\n",
    "\n",
    "vl = np.array([[x[0],x[1],int(n)] for n,x in enumerate(X) if (x[0] < 0.3 and (x[1] < -0.3 or x[1] > 0.3))])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in vl[:, 2]]\n",
    "plt.scatter(vl[:, 0], vl[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Vertical left\")\n",
    "plt.show()\n",
    "\n",
    "hb = np.array([[x[0],x[1],int(n)] for n,x in enumerate(X) if (x[1] < 0.3 and (x[0] < -0.3 or x[0] > 0.3))])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in hb[:, 2]]\n",
    "plt.scatter(hb[:, 0], hb[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Horizontal bottom\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On était bloqué la wola\n",
    "train_linear_classification_model(model_vl, input_dim, vl[:, :-1], Y[vl[:,-1].astype(int)], epochs=100000)\n",
    "train_linear_classification_model(model_vr, input_dim, vr[:, :-1], Y[vr[:,-1].astype(int)], epochs=100000)\n",
    "train_linear_classification_model(model_ht, input_dim, ht[:, :-1], Y[ht[:,-1].astype(int)], epochs=100000)\n",
    "train_linear_classification_model(model_hb, input_dim, hb[:, :-1], Y[hb[:,-1].astype(int)], epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs_vl = [predict_linear_model_classif(model_vl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_vr = [predict_linear_model_classif(model_vr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_ht = [predict_linear_model_classif(model_ht, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_hb = [predict_linear_model_classif(model_hb, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if (vl == 1 and vr == 1) or (ht == 1 and hb == 1) else 'red' for (vl, vr, ht, hb) in zip(predicted_outputs_vl, predicted_outputs_vr, predicted_outputs_ht, predicted_outputs_hb)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "destroy_linear_model(model_vl)\n",
    "destroy_linear_model(model_vr)\n",
    "destroy_linear_model(model_ht)\n",
    "destroy_linear_model(model_hb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333c1c0",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a108d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0])*2, 1]\n",
    "\n",
    "p_model, _ = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [0, 0])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [0, 0])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f9931",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8461815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-2, 2, 0.1) for x2 in np.arange(-2, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y, alpha=0.01, epochs=200000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model , [1, 1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cefa9",
   "metadata": {},
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f1cde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 30\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if coord >= 0 else [0,1] for coord in Y]\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0533d",
   "metadata": {
    "id": "v4hhnYge928d"
   },
   "source": [
    "### Multi Linear 3 classes :\n",
    "        Linear Model x3 : OK\n",
    "        MLP (2, 3)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303bffc1",
   "metadata": {
    "id": "IvhvqkDw928q"
   },
   "outputs": [],
   "source": [
    "X = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "Y = np.array([[1, 0, 0] if -p[0] - p[1] - 0.5 > 0 and p[1] < 0 and p[0] - p[1] - 0.5 < 0 else # bleu\n",
    "              [0, 1, 0] if -p[0] - p[1] - 0.5 < 0 and p[1] > 0 and p[0] - p[1] - 0.5 < 0 else # rouge\n",
    "              [0, 0, 1] if -p[0] - p[1] - 0.5 < 0 and p[1] < 0 and p[0] - p[1] - 0.5 > 0 else # vert\n",
    "              [0, 0, 0]for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ef9f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "4aqzcUlJ928s",
    "outputId": "71df307b-e9c9-4a2d-a942-b75e3a141e46"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,1], color='blue')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,1], color='red')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,1], color='green')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e96eb5",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b54605",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, [-0.75, -0.50])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "flattened_Y = Y[-1].flatten()\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, flattened_Y)\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim, [-0.75, -0.50])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91200b9f",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "\n",
    "model_dr = create_linear_model(input_dim)\n",
    "model_dl = create_linear_model(input_dim)\n",
    "model_h = create_linear_model(input_dim)\n",
    "\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1.5, 1.5, 0.1) for x2 in np.arange(-1.5, 1.5, 0.1)]\n",
    "colors = [\"blue\" if output[0] == 1 else (\"red\" if output[1] == 1 else (\"green\" if output[2] == 1 else \"black\")) for output in Y]\n",
    "\n",
    "dr = np.array([1 if y[2] == 1 else -1 for y in Y])\n",
    "h = np.array([1 if y[1] == 1 else -1 for y in Y])\n",
    "dl = np.array([1 if y[0] == 1 else -1 for y in Y])\n",
    "\n",
    "predicted_outputs_dr = [predict_linear_model_classif(model_dr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_dl = [predict_linear_model_classif(model_dl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_h = [predict_linear_model_classif(model_h, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "\n",
    "predicted_outputs_colors = ['green' if (dr == 1 and dl == -1 and h == -1) else (\"blue\" if (dl == 1 and dr == -1 and h == -1) else (\"red\" if (h == 1 and dr == -1 and dl == -1) else \"black\")) for (dr, dl, h) in zip(predicted_outputs_dr, predicted_outputs_dl, predicted_outputs_h)]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=40)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "flattened_dataset_outputs = []\n",
    "for p in Y:\n",
    "    flattened_dataset_outputs.append(p[0])\n",
    "    flattened_dataset_outputs.append(p[1])\n",
    "    flattened_dataset_outputs.append(p[2])\n",
    "    \n",
    "\n",
    "train_linear_classification_model(model_dl, input_dim, X, dl, alpha=0.01, epochs=100000)\n",
    "train_linear_classification_model(model_dr, input_dim, X, dr, alpha=0.01, epochs=100000)\n",
    "train_linear_classification_model(model_h, input_dim, X, h, alpha=0.01, epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs_dr = [predict_linear_model_classif(model_dr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_dl = [predict_linear_model_classif(model_dl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_h = [predict_linear_model_classif(model_h, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['green' if (dr == 1 and dl == -1 and h == -1) else (\"blue\" if (dl == 1 and dr == -1 and h == -1) else (\"red\" if (h == 1 and dr == -1 and dl == -1) else \"black\")) for (dr, dl, h) in zip(predicted_outputs_dr, predicted_outputs_dl, predicted_outputs_h)]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0aaa73",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 3]\n",
    "\n",
    "p_model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, np.array([-0.75, -0.50]), len_output_layer)\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y.flatten())\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, np.array([-0.75, -0.50]), len_output_layer)\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246d1cd",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ffebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 3]\n",
    "\n",
    "model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1.5, 1.6, 0.2) for x2 in np.arange(-1.5, 1.6, 0.2)]\n",
    "colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=50)\n",
    "plt.show()\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y.flatten())\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=50)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b407155",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41637bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "k = 30\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output)\n",
    "\n",
    "#colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] and predict[0] > predict[2] else ('red' if predict[1] > predict[2] else 'green') for predict in [predict_rbfn(model, coord, 3) for coord in plot_input]]\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e51a12",
   "metadata": {
    "id": "uKFBx2m066i2"
   },
   "source": [
    "### Multi Cross :\n",
    "        Linear Model x3 : KO\n",
    "        MLP (2, ?, ?, 3): OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71dad19",
   "metadata": {
    "id": "0ZE8OW-K66i5"
   },
   "outputs": [],
   "source": [
    "X = np.random.random((1000, 2)) * 2.0 - 1.0\n",
    "Y = np.array([[1, 0, 0] if abs(p[0] % 0.5) <= 0.25 and abs(p[1] % 0.5) > 0.25 else [0, 1, 0] if abs(p[0] % 0.5) > 0.25 and abs(p[1] % 0.5) <= 0.25 else [0, 0, 1] for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa1642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "55U95UMS66i6",
    "outputId": "f14df72f-c2c1-4498-9668-f91f29594b06"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,1], color='blue')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,1], color='red')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,1], color='green')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6647bc7",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "Impossible de classer tous ces groupes\n",
    "avec uniquement 3 “droites”, on a alors transformé les entrées de notre\n",
    "modèle pour n’avoir qu’une instance des quatre groupes qui se répétaient à\n",
    "l’infini sur l’ensemble d’origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim , [2, 2])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "flattened_X = X.flatten()\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, flattened_X, Y)\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [2, 2])\n",
    "\n",
    "print(\"After training:\",test_after)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0b8db",
   "metadata": {},
   "source": [
    "### Linear model (advanced)\n",
    "\n",
    "Ne fonctionne pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6feed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = create_linear_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in range(1, 2) for x2 in range(1, 2)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_linear_classification_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model,input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [1.25, 1.25])\n",
    "\n",
    "print(\"Prediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_linear_model(model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e9529",
   "metadata": {},
   "source": [
    "### MLP (simple)\n",
    "\n",
    "Nous avons cherché à augmenter le nombre de\n",
    "neurones par couche jusqu’à ne plus observer qu’une stagnation des\n",
    "performances de traitement contre un temps de traitement croissant. On a\n",
    "considéré qu’une forme de (2,64,64,3) était un bon compromis\n",
    "performances/rapidité. Il a cependant fallu travailler sur le nombre\n",
    "d'époques ainsi que sur la correction apportée à chaque époque pour\n",
    "favoriser l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]),2,2,3]\n",
    "\n",
    "p_model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [2.5, 2.5], len_output_layer)\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y.flatten(), epochs=10000)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [2.5, 2.5], len_output_layer)\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83cfba",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]),26,26,3]\n",
    "\n",
    "\n",
    "model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-2, 2,0.1) for x2 in np.arange(-2, 2, 0.1)]\n",
    "colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y.flatten(), alpha=0.03, epochs=1000000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41251b16",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86363c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "k = 100\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output)\n",
    "\n",
    "#colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = np.random.random((1000, 2)) * 2.0 - 1.0\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] and predict[0] > predict[2] else ('red' if predict[1] > predict[2] else 'green') for predict in [predict_rbfn(model, coord, 3) for coord in plot_input]]\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9961ee",
   "metadata": {
    "id": "zyrivJMK_WOQ"
   },
   "source": [
    "## Régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78a949",
   "metadata": {
    "id": "p4EB787A_WOR"
   },
   "source": [
    "### Linear Simple 2D :\n",
    "        Linear Model : OK\n",
    "        MLP (1, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525ad99",
   "metadata": {
    "id": "dan93I7A_WOR"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1],\n",
    "      [2]\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744654b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "6vHbCksm_sQU",
    "outputId": "1e476e34-d3ef-456a-c46e-62de28756946"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ea359",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f75c9",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 5, 0, 5])\n",
    "plt.show()\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 5, 0, 5])\n",
    "plt.show()\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c614a8",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 1])    \n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y)\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bdd90",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 1])    \n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([-10, 10, -10, 10])\n",
    "plt.show()\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([-10, 10, -10, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80113f9",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 2\n",
    "input_dim = 1\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.random.random((100, 1)) * 4.0\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, 1) for coord in plot_input]]\n",
    "plt.scatter(plot_input, plot_output_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeecfd9",
   "metadata": {
    "id": "CkFb79fq_6ci"
   },
   "source": [
    "### Non Linear Simple 2D :\n",
    "        Linear Model    : OK\n",
    "        MLP (1, ?, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a748e0",
   "metadata": {
    "id": "sZqi1Yy3_6cj"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1],\n",
    "      [2],\n",
    "      [3]\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      3,\n",
    "      2.5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b270b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "NSqXDh6c_6ck",
    "outputId": "5e07562b-4b2f-4dc9-b4bd-263ac1b778fd"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e6ba6",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f07fe",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4961344",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 4, 0, 4])\n",
    "plt.show()\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 4, 0, 4])\n",
    "plt.show()\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4e5ae",
   "metadata": {},
   "source": [
    "### MLP (simple)\n",
    "\n",
    "On a décidé de mettre 1 couche cachée\n",
    "de 2 neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 1, 1])    \n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y)\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3114191",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec38368",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 2, 1])    \n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0,4,0,4])\n",
    "plt.show()\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               epochs=1000000)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0,4,0,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318044c3",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c00d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 3\n",
    "input_dim = 1\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.random.random((100, 1)) * 4.0\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, 1) for coord in plot_input]]\n",
    "plt.scatter(plot_input, plot_output_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6cd32a",
   "metadata": {
    "id": "WT1s5lZxAJuL"
   },
   "source": [
    "### Linear Simple 3D :\n",
    "        Linear Model    : OK\n",
    "        MLP (2, 1)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe9f40",
   "metadata": {
    "id": "KL_IanGMAJuM"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1, 1],\n",
    "      [2, 2],\n",
    "      [6, 1]\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      3,\n",
    "      5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4070fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "91dQpMIzAJuO",
    "outputId": "c1681d4c-3b99-429c-fa3f-6b8ef879e0de"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#!pip install plotly\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0],X[:,1],Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e06070",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "Sachant que notre matrice d’input était\n",
    "{(1,2,3},(1,2,3)} , les deux colonnes sont donc des combinaisons linéaire l’une\n",
    "de l’autre (C1 = C2 ; L2 = 2L1...) de ce fait lors de l'exécution plus avant de la\n",
    "librairie il nous est impossible de réaliser l’inverse cette matrice. Pour\n",
    "contrer ce problème nous avons découvert qu’il était possible de dupliquer\n",
    "une des lignes du dataset pour briser cette restriction sans créer de nouvelle\n",
    "datas.\n",
    "Une autre possibilité proposée mais moins sur car elle ajoutait de nouvelles\n",
    "données au dataset. Les nouveaux points étaient des jumeaux des points\n",
    "déjà existant avec des coordonnées décaler sur le repère à l’échelle de\n",
    "0.00001 pour minimiser l’impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b6f5c",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "    \n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ccc5d",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c734f16",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1] \n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "    \n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0] for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0]  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654a8d",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 3\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, num_classes) for coord in plot_input]]\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(plot_input))], \"x0\": plot_input[:, 0], \"x1\": plot_input[:, 1], \"z_aft\":plot_output_value})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7187e0c",
   "metadata": {
    "id": "kO361TllBqbm"
   },
   "source": [
    "### Linear Tricky 3D :\n",
    "        Linear Model    : OK\n",
    "        MLP (2, 1)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dd0bb",
   "metadata": {
    "id": "nR_i7qLxBqbm"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1, 1],\n",
    "      [2, 2],\n",
    "      [3, 3]\n",
    "])\n",
    "Y = np.array([\n",
    "      1,\n",
    "      2,\n",
    "      3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c9eb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "dHriVYrKBqbo",
    "outputId": "681a33c5-8ad5-427a-beea-eaf2a4e268ac"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0],X[:,1],Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f3caf",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654f900",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0]) # 2\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "    \n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "#print(df.head())\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318acec",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               epochs=100000)\n",
    "\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9501d0",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "    \n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0] for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0]  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b1a19",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078adab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 3\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, num_classes) for coord in plot_input]]\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(plot_input))], \"x0\": plot_input[:, 0], \"x1\": plot_input[:, 1], \"z_aft\":plot_output_value})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb662bd",
   "metadata": {
    "id": "H_h0_vtCBEzk"
   },
   "source": [
    "### Non Linear Simple 3D :\n",
    "        Linear Model       : KO\n",
    "        MLP (2, 2, 1)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb42013",
   "metadata": {
    "id": "ij70I1H9BEzk"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1, 0],\n",
    "      [0, 1],\n",
    "      [1, 1],\n",
    "      [0, 0],\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      1,\n",
    "      -2,\n",
    "      -1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075efbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "N3VDOby8BEzn",
    "outputId": "ef903fb3-08ed-4afd-f1e0-bcaed828b118"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0],X[:,1],Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604005b8",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df13190",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [1, 0])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [1, 0])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67df0",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "    \n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447813c7",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [1, 0])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               epochs=100000)\n",
    "\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [1, 0])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333923d",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "    \n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0] for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               alpha=0.01,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0]  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29756783",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10feb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 4\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.array([[i, j] for i in np.arange(0, 2, 0.1) for j in np.arange(0, 2, 0.1)])\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, num_classes) for coord in plot_input]]\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(plot_input))], \"x0\": plot_input[:, 0], \"x1\": plot_input[:, 1], \"z_aft\":plot_output_value})\n",
    "\n",
    "#old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "#df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
