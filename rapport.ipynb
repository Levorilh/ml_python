{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14874ee2",
   "metadata": {},
   "source": [
    "# Rapport interactif\n",
    "\n",
    "### Sommaire\n",
    "I. Implémentation sur notre dataset\n",
    "\n",
    "II. Cas de tests\n",
    "\n",
    "### Rappel du sujet\n",
    "\n",
    "Nous essayerons de répondre à la problématique: \n",
    "- **Quel est ce monument parisien ?**\n",
    "\n",
    "À partir de notre dataset.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Nous avons utilisés une extension Chrome qui récupère entre 400 et 500 images à partir d'une recherche, puis nous avons nettoyés certaines images incohérentes. \n",
    "\n",
    "\n",
    "### Librairie\n",
    "\n",
    "Nous avons réalisé **ML**, notre propre librairie de machine learning en C++. Elle dépend de la bibliothèque **Eigen**, qui nous sert à réaliser plus facilement des calculs matriciels.\n",
    "\n",
    "### Application web\n",
    "\n",
    "Nous avons décidé de réaliser notre application web en Python en utilisant le micro-framework **Flask** ainsi que **Bootstrap** et **JQuery**\n",
    "\n",
    "### Étapes de développement\n",
    "\n",
    "1. Implémentation du perceptron\n",
    "2. Interopérabilité du perceptron\n",
    "3. Implémentation du perceptron multi-couches\n",
    "4. Interopérabilité du perceptron multi-couches\n",
    "5. Validation sur les cas de tests et correction de la librairie\n",
    "6. Rédaction de la première version du rapport pour l'étape n°2\n",
    "7. Création du site web\n",
    "8. Ajout des fonctionnalités save et load sur le percepetron\n",
    "9. Interopérabilité du save et du load sur le perceptron\n",
    "10. Ajout des fonctionnalités save et load sur le perceptron multi-couches\n",
    "11. Interopérabilité du save et du load sur le perceptron multi-couches\n",
    "12. Amélioration et finition du site web (*en cours*)\n",
    "13. Implémentation du Radial Basis Function Network (*en cours*)\n",
    "14. Rédaction du rapport interactif (*en cours*)\n",
    "15. Interopérabilité du Radial Basis Function Network (*à venir*)\n",
    "\n",
    "### Difficultés rencontrées\n",
    "\n",
    "- Problème d’initialisation des valeurs aléatoires, on avait des modèles tous identiques.\n",
    "- Tentative d’utiliser std::random_device pour obtenir des valeurs aléatoires plus uniformes. Cela fonctionnait mais on s’est rendus compte que rand() de stdlib suffisait pour notre besoin.\n",
    "- Confusions due au biais (on a tenté de le supprimer plusieurs fois)\n",
    "- Erreur d’allocation de mémoire entraînant des erreurs lors du passages des objets par l'interopérabilité\n",
    "- Destruction d'une instance d'un perceptron multi-couches, mal paramétré entraînant des erreurs lors de l’utilisation de l'interopérabilité.\n",
    "- Prise en main de NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdaaf91",
   "metadata": {},
   "source": [
    "# Partie 1. Implémentation sur notre dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2da79d",
   "metadata": {},
   "source": [
    "Dans cette partie, nous montrerons l'étape de pré-traitement des données (*data preprocessing*), puis nous appliquerons notre modéle linéaire ainsi que notre perceptron multi-couches à notre dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346e3e6",
   "metadata": {},
   "source": [
    "## a) Importer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fded975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfbf24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (64, 64)\n",
    "PATH = os.path.join(\"data_large/\")\n",
    "TRAIN = os.path.join(PATH, \"train\")\n",
    "classes = os.listdir(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89634d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les différentes classes possibles sont: moulin-rouge, palais-de-l-elysee, pont-neuf, place-de-la-concorde, jardin-des-tuileries, hotel-de-ville, arc-de-triomphe, musee-d-orsay\n"
     ]
    }
   ],
   "source": [
    "print(f\"Les différentes classes possibles sont: {', '.join(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7056f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_images_and_assign_labels(folder, label, X, Y, IMG_SIZE=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Convertit et redimensionne les images d'un dossier en NumPy Array.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        im = Image.open(image_path)\n",
    "        im = im.resize(IMG_SIZE)\n",
    "        im = im.convert(\"RGB\")\n",
    "        im_arr = np.array(im)\n",
    "        im_arr = np.reshape(im_arr, (IMG_SIZE[0]* IMG_SIZE[1] * 3,))\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cefe14ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images par classes dans le train set:\n",
      "- moulin-rouge: 391\n",
      "- palais-de-l-elysee: 441\n",
      "- pont-neuf: 487\n",
      "- place-de-la-concorde: 457\n",
      "- jardin-des-tuileries: 393\n",
      "- hotel-de-ville: 359\n",
      "- arc-de-triomphe: 471\n",
      "- musee-d-orsay: 418\n",
      "\n",
      "Nombre d'images par classes dans le valid set:\n",
      "- moulin-rouge: 129\n",
      "- palais-de-l-elysee: 129\n",
      "- pont-neuf: 129\n",
      "- place-de-la-concorde: 129\n",
      "- jardin-des-tuileries: 129\n",
      "- hotel-de-ville: 129\n",
      "- arc-de-triomphe: 129\n",
      "- musee-d-orsay: 129\n",
      "\n",
      "Nombre d'images dans le test set:\n",
      "1041\n"
     ]
    }
   ],
   "source": [
    "for s in [\"train\", \"valid\", \"test\"]:\n",
    "    if s == \"test\":\n",
    "        print(f\"Nombre d'images dans le {s} set:\")\n",
    "        print(f\"{len(os.listdir(os.path.join(PATH, s)))}\")\n",
    "    else:\n",
    "        print(f\"Nombre d'images par classes dans le {s} set:\")\n",
    "        for cl in classes:\n",
    "            print(f\"- {cl}: {len(os.listdir(os.path.join(PATH, s, cl)))}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f7a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(IMG_SIZE=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Crée les datasets d'entrainement et de validation\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_valid, y_valid = [], [], [], []\n",
    "    labels = np.identity(len(os.listdir(TRAIN)))        \n",
    "    for set_type in [\"train\", \"valid\"]:\n",
    "        for cl, lab in zip(classes, labels):\n",
    "            if set_type == \"train\":\n",
    "                X_set, y_set = X_train, y_train\n",
    "            else:\n",
    "                X_set, y_set = X_valid, y_valid\n",
    "            import_images_and_assign_labels(\n",
    "                os.path.join(PATH, set_type, cl),\n",
    "                lab,\n",
    "                X_set,\n",
    "                y_set,\n",
    "                IMG_SIZE\n",
    "            )                \n",
    "    \n",
    "    return (np.array(X_train) / 255.0, np.array(y_train)), \\\n",
    "           (np.array(X_valid) / 255.0, np.array(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945813bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98fba64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(tensor, label, prediction):\n",
    "    \"\"\"\n",
    "    Affiche une image avec sa prediction et label\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(tensor.reshape((IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    ax.set_title(f'Label: {classes[np.argmax(label)]}')\n",
    "    ax.set_xlabel(f'Prediction: {np.argmax(prediction)} / Expected output: {np.argmax(label)}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([]);\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732db63",
   "metadata": {},
   "source": [
    "## b) Appliquer le modéle linéaire au dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "507ef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0321b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = create_linear_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20f8bdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: -1.0\n"
     ]
    }
   ],
   "source": [
    "picture_test_linear = np.random.randint(0, len(X_train))\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, X_train[picture_test_linear])\n",
    "print(\"Before training:\", test_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfd3e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_linear_classification_model(p_model, input_dim, X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f724ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training: -1.0\n"
     ]
    }
   ],
   "source": [
    "test_after = predict_linear_model_classif(p_model, input_dim, X_train[picture_test])\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8502c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_linear_model(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345f8b9",
   "metadata": {},
   "source": [
    "## c) Appliquer le PMC au dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb85fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0043ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X_train[0]), 32, NUM_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea72e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model, len_output_layer = create_mlp_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aba8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_train)\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output_layer)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    print(f\"Accuracy training: {round((true_preds / total_preds) * 100, 2)}%\")\n",
    "    \n",
    "    true_preds = 0\n",
    "    total_preds = len(X_valid)\n",
    "    for x, y in zip(X_valid, y_valid):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output_layer)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    print(f\"Accuracy valid: {round((true_preds / total_preds) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ace1476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: [0.9999815, -0.99973845, -0.99952537, 0.8999741, -0.8593494, -0.9972533, 0.84355825, 1.0]\n"
     ]
    }
   ],
   "source": [
    "test_before = predict_mlp_model_classification(p_model, X_valid[picture_test], len_output_layer)\n",
    "print(\"Before training:\", test_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a07d599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showImg(X_valid[picture_test], y_valid[picture_test], test_before);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69a32c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx_train = [np.random.randint(0, len(X_train) - 1) for _ in range(50)]\n",
    "random_idx_valid = [np.random.randint(0, len(X_valid) - 1) for _ in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d94f254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3417 3417\n",
      "1032 1032\n",
      "[1431, 126, 3068, 300, 1556, 3405, 390, 341, 1395, 949, 2001, 1406, 781, 502, 767, 223, 3302, 1840, 2639, 45, 2828, 1776, 1842, 2293, 1927, 1836, 968, 517, 1226, 2653, 1558, 1828, 295, 79, 3014, 3018, 1948, 1472, 812, 23, 1008, 691, 144, 2496, 2765, 2, 914, 2730, 2718, 3188]\n",
      "[241, 298, 242, 912, 751, 127, 282, 977, 62, 919, 392, 795, 629, 571, 394, 64, 272, 597, 1007, 756, 205, 159, 67, 396, 429, 192, 154, 832, 902, 1026, 223, 882, 224, 747, 186, 338, 143, 592, 741, 232, 28, 309, 988, 180, 917, 804, 165, 893, 749, 521]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_valid), len(y_valid))\n",
    "\n",
    "print(random_idx_train)\n",
    "print(random_idx_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab25861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training: 10.77%\n",
      "Accuracy valid: 10.66%\n"
     ]
    }
   ],
   "source": [
    "accuracy(p_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e4d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy(X_valid[random_idx_valid, :], y_valid[random_idx_valid, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "657693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X_train, y_train.flatten(), epochs=1000)#, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88e52cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mlp_model(p_model, \"mlp_10000_768_128.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa1568c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_mlp_model(p_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c8b99c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETS GO\n"
     ]
    }
   ],
   "source": [
    "p_model2 = load_mlp_model(\"mlp_10000_768_128.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e7018e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21568627 0.35686275 0.56862745 0.23137255 0.36862745 0.58039216\n",
      " 0.24313725 0.38039216 0.59215686 0.25490196 0.39215686 0.60784314\n",
      " 0.2627451  0.4        0.61960784 0.26666667 0.40392157 0.62352941\n",
      " 0.27058824 0.40784314 0.62745098 0.27058824 0.41176471 0.63921569\n",
      " 0.27058824 0.41568627 0.64313725 0.28235294 0.41960784 0.62745098\n",
      " 0.27058824 0.41568627 0.61568627 0.2627451  0.40784314 0.61568627\n",
      " 0.2745098  0.41176471 0.62352941 0.26666667 0.4        0.61176471\n",
      " 0.30196078 0.41568627 0.59607843 0.4745098  0.51764706 0.6\n",
      " 0.24313725 0.38431373 0.58431373 0.25490196 0.39215686 0.6\n",
      " 0.26666667 0.40392157 0.61568627 0.27058824 0.41176471 0.63137255\n",
      " 0.27843137 0.41960784 0.63921569 0.28235294 0.42352941 0.65098039\n",
      " 0.28627451 0.43529412 0.65882353 0.32156863 0.44705882 0.63921569\n",
      " 0.38823529 0.45490196 0.55294118 0.4745098  0.45882353 0.45490196\n",
      " 0.34117647 0.41960784 0.54901961 0.29019608 0.42352941 0.64313725\n",
      " 0.29803922 0.42745098 0.63137255 0.28627451 0.41568627 0.62352941\n",
      " 0.27843137 0.40784314 0.59607843 0.39215686 0.46666667 0.58823529\n",
      " 0.26666667 0.40392157 0.60392157 0.27843137 0.41568627 0.62352941\n",
      " 0.29411765 0.42745098 0.64313725 0.30588235 0.43529412 0.6627451\n",
      " 0.30980392 0.44705882 0.67843137 0.35294118 0.45490196 0.63137255\n",
      " 0.43529412 0.46666667 0.52941176 0.55686275 0.51372549 0.47843137\n",
      " 0.69019608 0.62352941 0.54509804 0.81568627 0.72941176 0.63921569\n",
      " 0.48235294 0.49411765 0.54901961 0.30588235 0.44313725 0.66666667\n",
      " 0.33333333 0.45882353 0.65882353 0.30980392 0.43529412 0.63529412\n",
      " 0.28235294 0.41568627 0.60784314 0.39215686 0.47058824 0.59215686\n",
      " 0.29411765 0.42352941 0.63529412 0.30980392 0.43921569 0.65098039\n",
      " 0.32941176 0.45490196 0.67058824 0.38039216 0.47058824 0.63529412\n",
      " 0.49019608 0.49019608 0.52156863 0.63137255 0.57254902 0.51764706\n",
      " 0.77254902 0.69803922 0.62352941 0.83137255 0.76078431 0.69019608\n",
      " 0.73333333 0.6627451  0.6        0.54509804 0.47058824 0.40784314\n",
      " 0.41176471 0.38039216 0.37647059 0.55686275 0.61960784 0.7372549\n",
      " 0.39215686 0.50588235 0.69019608 0.32941176 0.45490196 0.65490196\n",
      " 0.31764706 0.44313725 0.63137255 0.44313725 0.50980392 0.63529412\n",
      " 0.3372549  0.45098039 0.6627451  0.34509804 0.4627451  0.67843137\n",
      " 0.35686275 0.47843137 0.69411765 0.59215686 0.59607843 0.62352941\n",
      " 0.81176471 0.72941176 0.63921569 0.76470588 0.69411765 0.61960784\n",
      " 0.59607843 0.53333333 0.46666667 0.42352941 0.36078431 0.30196078\n",
      " 0.36470588 0.30588235 0.24705882 0.43529412 0.36470588 0.30588235\n",
      " 0.40392157 0.34901961 0.30196078 0.77647059 0.76470588 0.76078431\n",
      " 0.49019608 0.57254902 0.72941176 0.39215686 0.49411765 0.68235294\n",
      " 0.35686275 0.46666667 0.65098039 0.39607843 0.48627451 0.63921569\n",
      " 0.5254902  0.58823529 0.70588235 0.37254902 0.49411765 0.68627451\n",
      " 0.39607843 0.50980392 0.69019608 0.56470588 0.5372549  0.52941176\n",
      " 0.48235294 0.41568627 0.35686275 0.40392157 0.3372549  0.2745098\n",
      " 0.45490196 0.37254902 0.30196078 0.57254902 0.49411765 0.41568627\n",
      " 0.75686275 0.68627451 0.60392157 0.84313725 0.77254902 0.69411765\n",
      " 0.59607843 0.53333333 0.4627451  0.57254902 0.58039216 0.60784314\n",
      " 0.55294118 0.62745098 0.75294118 0.65098039 0.6745098  0.74509804\n",
      " 0.40784314 0.50980392 0.6745098  0.37254902 0.48235294 0.64705882\n",
      " 0.49803922 0.57254902 0.69803922 0.4745098  0.56470588 0.71372549\n",
      " 0.43137255 0.54509804 0.71764706 0.48235294 0.47058824 0.4745098\n",
      " 0.65098039 0.57254902 0.49019608 0.64705882 0.57254902 0.49411765\n",
      " 0.6        0.5254902  0.45882353 0.68235294 0.60784314 0.5372549\n",
      " 0.72156863 0.65098039 0.57647059 0.69019608 0.62352941 0.54901961\n",
      " 0.71764706 0.65490196 0.59215686 0.65882353 0.64705882 0.6627451\n",
      " 0.65098039 0.68627451 0.76078431 0.70588235 0.71372549 0.75294118\n",
      " 0.47843137 0.56078431 0.69411765 0.39215686 0.49411765 0.65098039\n",
      " 0.52941176 0.6        0.70196078 0.47843137 0.57254902 0.71372549\n",
      " 0.47843137 0.58431373 0.74117647 0.68627451 0.68235294 0.69803922\n",
      " 0.79215686 0.71764706 0.63921569 0.66666667 0.6        0.51764706\n",
      " 0.23137255 0.18823529 0.14901961 0.58431373 0.54117647 0.47843137\n",
      " 0.81176471 0.74117647 0.65490196 0.81568627 0.75294118 0.6745098\n",
      " 0.77647059 0.71764706 0.65882353 0.76862745 0.76078431 0.77254902\n",
      " 0.72941176 0.7372549  0.77254902 0.63529412 0.67058824 0.7372549\n",
      " 0.47843137 0.56470588 0.69803922 0.49803922 0.56470588 0.68235294\n",
      " 0.54901961 0.61568627 0.69803922 0.49803922 0.6        0.72156863\n",
      " 0.59607843 0.6627451  0.76078431 0.78039216 0.7372549  0.70588235\n",
      " 0.83137255 0.74509804 0.64313725 0.58431373 0.53333333 0.45882353\n",
      " 0.09803922 0.05490196 0.02352941 0.37254902 0.34117647 0.30196078\n",
      " 0.71372549 0.65882353 0.6        0.65882353 0.60392157 0.54901961\n",
      " 0.61568627 0.57254902 0.50980392 0.74509804 0.74509804 0.76862745\n",
      " 0.75686275 0.75686275 0.78039216 0.62745098 0.67058824 0.74117647\n",
      " 0.49803922 0.58431373 0.70980392 0.57254902 0.61568627 0.70196078\n",
      " 0.54901961 0.62352941 0.71764706 0.52941176 0.63137255 0.73333333\n",
      " 0.58823529 0.66666667 0.75686275 0.68627451 0.67058824 0.65098039\n",
      " 0.70196078 0.64313725 0.57647059 0.49803922 0.44313725 0.39215686\n",
      " 0.15686275 0.13333333 0.10980392 0.55294118 0.56862745 0.57254902\n",
      " 0.79607843 0.7254902  0.65098039 0.85098039 0.78431373 0.71764706\n",
      " 0.69803922 0.63921569 0.58823529 0.63921569 0.65490196 0.69411765\n",
      " 0.70980392 0.73333333 0.76862745 0.56862745 0.64705882 0.72941176\n",
      " 0.50196078 0.6        0.70980392 0.50980392 0.58039216 0.68627451\n",
      " 0.53333333 0.61960784 0.70588235 0.56078431 0.64313725 0.72941176\n",
      " 0.60392157 0.67843137 0.75686275 0.72941176 0.72156863 0.69803922\n",
      " 0.85882353 0.78823529 0.70980392 0.81568627 0.74117647 0.6627451\n",
      " 0.23921569 0.21568627 0.18823529 0.7254902  0.75294118 0.76470588\n",
      " 0.85098039 0.78431373 0.70980392 0.78823529 0.71764706 0.64705882\n",
      " 0.81568627 0.75294118 0.68627451 0.68235294 0.69411765 0.72941176\n",
      " 0.72156863 0.72941176 0.76078431 0.69019608 0.70980392 0.75294118\n",
      " 0.52941176 0.61960784 0.70196078 0.55294118 0.61568627 0.67058824\n",
      " 0.59607843 0.65490196 0.70588235 0.63921569 0.68627451 0.7254902\n",
      " 0.65098039 0.69411765 0.75294118 0.76470588 0.74117647 0.71764706\n",
      " 0.83137255 0.75686275 0.68627451 0.81960784 0.75686275 0.69019608\n",
      " 0.2745098  0.24705882 0.21568627 0.76862745 0.77254902 0.76470588\n",
      " 0.78431373 0.72156863 0.64705882 0.76862745 0.71372549 0.64313725\n",
      " 0.90980392 0.84313725 0.76862745 0.81960784 0.78431373 0.76470588\n",
      " 0.70196078 0.71372549 0.7372549  0.72156863 0.71372549 0.73333333\n",
      " 0.62352941 0.67058824 0.71764706 0.54509804 0.61960784 0.68235294\n",
      " 0.61960784 0.63137255 0.6627451  0.69803922 0.70196078 0.72156863\n",
      " 0.6745098  0.70588235 0.74117647 0.76078431 0.72941176 0.69803922\n",
      " 0.78431373 0.71372549 0.63921569 0.85098039 0.78431373 0.71764706\n",
      " 0.49411765 0.43921569 0.38431373 0.83529412 0.78823529 0.76078431\n",
      " 0.74901961 0.69019608 0.62352941 0.74117647 0.68235294 0.61568627\n",
      " 0.95686275 0.89411765 0.82352941 0.78039216 0.76470588 0.75294118\n",
      " 0.7254902  0.71764706 0.72941176 0.6627451  0.66666667 0.69411765\n",
      " 0.50980392 0.53333333 0.54117647 0.45098039 0.4745098  0.48235294\n",
      " 0.52156863 0.47058824 0.40784314 0.51372549 0.52156863 0.49019608\n",
      " 0.50588235 0.50196078 0.45490196 0.65490196 0.61568627 0.54901961\n",
      " 0.8627451  0.79607843 0.72156863 0.94901961 0.8627451  0.77254902\n",
      " 0.76470588 0.67843137 0.58823529 0.71764706 0.68235294 0.63137255\n",
      " 0.81568627 0.75686275 0.68627451 0.86666667 0.8        0.7254902\n",
      " 0.91764706 0.85490196 0.78039216 0.66666667 0.67058824 0.65098039\n",
      " 0.64313725 0.65490196 0.6627451  0.55294118 0.52941176 0.51372549\n",
      " 0.3254902  0.30196078 0.23137255 0.29803922 0.29411765 0.20392157\n",
      " 0.27058824 0.27058824 0.21176471 0.30980392 0.29411765 0.21568627\n",
      " 0.24313725 0.23529412 0.14117647 0.66666667 0.62352941 0.55294118\n",
      " 0.90196078 0.84313725 0.78431373 0.83921569 0.78039216 0.70196078\n",
      " 0.67058824 0.60784314 0.51764706 0.56078431 0.5254902  0.44313725\n",
      " 0.8627451  0.80392157 0.73333333 0.84705882 0.81176471 0.74901961\n",
      " 0.89019608 0.83137255 0.76470588 0.50196078 0.48627451 0.42745098\n",
      " 0.34509804 0.33333333 0.28627451 0.29411765 0.2627451  0.19607843\n",
      " 0.24313725 0.23921569 0.17254902 0.16862745 0.18039216 0.1372549\n",
      " 0.34117647 0.31764706 0.29411765 0.43921569 0.40392157 0.37647059\n",
      " 0.37254902 0.32941176 0.28627451 0.46666667 0.40392157 0.35294118\n",
      " 0.49411765 0.42745098 0.36862745 0.43921569 0.38823529 0.33333333\n",
      " 0.29019608 0.25490196 0.23137255 0.39215686 0.34117647 0.29019608\n",
      " 0.5254902  0.44705882 0.38823529 0.40784314 0.36470588 0.32941176\n",
      " 0.45882353 0.38823529 0.34509804 0.48627451 0.42352941 0.37254902\n",
      " 0.41568627 0.34117647 0.31372549 0.30980392 0.25490196 0.23921569\n",
      " 0.24313725 0.22352941 0.20392157 0.24313725 0.22745098 0.21568627]\n",
      "4980984640\n"
     ]
    }
   ],
   "source": [
    "input_dim[-1]\n",
    "print(X_valid[picture_test])\n",
    "print(p_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_after = predict_mlp_model_classification(p_model2, X_valid[picture_test], input_dim[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e148487",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_after' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8658e663aa16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After training:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class index : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class expected :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpicture_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_after' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"After training:\", test_after)\n",
    "print(\"Class index : \", np.argmax(test_after))\n",
    "print(\"Class expected :\", np.argmax(y_train[picture_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e498293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showImg(X_valid[picture_test], y_valid[picture_test], test_after);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118495c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(p_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_mlp_model(p_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba37735",
   "metadata": {},
   "source": [
    "## Part IV. Discover new MLP architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7d3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b800da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = [0, 1, 2, 3]\n",
    "hidden_layers = [8, 16, 32]\n",
    "size_img = [(8, 8), (16, 16), (32, 32)]\n",
    "EPOCHS = [100000, 150000, 200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c294429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_grid_search(model, len_output, X_tr, y_tr, X_val, y_val):\n",
    "    train_total, valid_total = len(X_train), len(X_valid)\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_tr)\n",
    "    for x, y in zip(X_tr, y_tr):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    train_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    true_preds = 0\n",
    "    total_preds = len(X_val)\n",
    "    for x, y in zip(X_val, y_val):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    valid_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    return train_acc, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f83eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: epochs=20000, img_size=(8, 8), input_dim=[8] -- Train acc: 13.81% / Valid_acc: 14.53%\n",
      "Model parameters: epochs=20000, img_size=(8, 8), input_dim=[16, 8] -- Train acc: 13.37% / Valid_acc: 12.5%\n",
      "Model parameters: epochs=20000, img_size=(8, 8), input_dim=[16, 64, 8] -- Train acc: 12.29% / Valid_acc: 13.76%\n",
      "Model parameters: epochs=20000, img_size=(8, 8), input_dim=[32, 64, 64, 8] -- Train acc: 15.83% / Valid_acc: 15.12%\n",
      "Model parameters: epochs=20000, img_size=(8, 8), input_dim=[32, 64, 32, 16, 8] -- Train acc: 15.42% / Valid_acc: 13.66%\n",
      "Model parameters: epochs=20000, img_size=(16, 16), input_dim=[8] -- Train acc: 17.27% / Valid_acc: 17.64%\n",
      "Model parameters: epochs=20000, img_size=(16, 16), input_dim=[16, 8] -- Train acc: 10.51% / Valid_acc: 12.5%\n",
      "Model parameters: epochs=20000, img_size=(16, 16), input_dim=[16, 16, 8] -- Train acc: 13.61% / Valid_acc: 13.47%\n",
      "Model parameters: epochs=20000, img_size=(16, 16), input_dim=[32, 64, 32, 8] -- Train acc: 15.1% / Valid_acc: 12.6%\n",
      "Model parameters: epochs=20000, img_size=(16, 16), input_dim=[16, 16, 32, 64, 8] -- Train acc: 11.5% / Valid_acc: 12.5%\n",
      "Model parameters: epochs=20000, img_size=(32, 32), input_dim=[8] -- Train acc: 9.31% / Valid_acc: 10.17%\n",
      "Model parameters: epochs=20000, img_size=(32, 32), input_dim=[64, 8] -- Train acc: 14.08% / Valid_acc: 12.98%\n",
      "Model parameters: epochs=20000, img_size=(32, 32), input_dim=[16, 64, 8] -- Train acc: 11.82% / Valid_acc: 13.66%\n",
      "Model parameters: epochs=20000, img_size=(32, 32), input_dim=[16, 32, 64, 8] -- Train acc: 13.67% / Valid_acc: 12.6%\n",
      "Model parameters: epochs=20000, img_size=(32, 32), input_dim=[32, 32, 64, 64, 8] -- Train acc: 11.59% / Valid_acc: 12.5%\n",
      "Model parameters: epochs=20000, img_size=(64, 64), input_dim=[8] -- Train acc: 10.92% / Valid_acc: 12.4%\n",
      "Model parameters: epochs=20000, img_size=(64, 64), input_dim=[16, 8] -- Train acc: 14.08% / Valid_acc: 13.28%\n",
      "Model parameters: epochs=20000, img_size=(64, 64), input_dim=[64, 32, 8] -- Train acc: 10.54% / Valid_acc: 12.5%\n",
      "Model parameters: epochs=20000, img_size=(64, 64), input_dim=[64, 16, 32, 8] -- Train acc: 14.66% / Valid_acc: 12.89%\n",
      "Model parameters: epochs=20000, img_size=(64, 64), input_dim=[64, 64, 32, 32, 8] -- Train acc: 13.78% / Valid_acc: 12.89%\n",
      "Max Train acc: 17.27% / Max Valid_acc: 17.64%\n",
      "Model parameters: epochs=35000, img_size=(8, 8), input_dim=[8] -- Train acc: 25.87% / Valid_acc: 24.52%\n",
      "Model parameters: epochs=35000, img_size=(8, 8), input_dim=[16, 8] -- Train acc: 17.5% / Valid_acc: 15.89%\n",
      "Model parameters: epochs=35000, img_size=(8, 8), input_dim=[16, 16, 8] -- Train acc: 15.57% / Valid_acc: 17.15%\n",
      "Model parameters: epochs=35000, img_size=(8, 8), input_dim=[64, 64, 64, 8] -- Train acc: 15.19% / Valid_acc: 13.86%\n",
      "Model parameters: epochs=35000, img_size=(8, 8), input_dim=[32, 16, 32, 64, 8] -- Train acc: 12.94% / Valid_acc: 12.5%\n",
      "Model parameters: epochs=35000, img_size=(16, 16), input_dim=[8] -- Train acc: 23.15% / Valid_acc: 19.86%\n",
      "Model parameters: epochs=35000, img_size=(16, 16), input_dim=[16, 8] -- Train acc: 13.67% / Valid_acc: 14.83%\n",
      "Model parameters: epochs=35000, img_size=(16, 16), input_dim=[64, 64, 8] -- Train acc: 14.46% / Valid_acc: 14.53%\n",
      "Model parameters: epochs=35000, img_size=(16, 16), input_dim=[64, 16, 32, 8] -- Train acc: 18.7% / Valid_acc: 17.34%\n",
      "Model parameters: epochs=35000, img_size=(16, 16), input_dim=[64, 64, 16, 64, 8] -- Train acc: 14.22% / Valid_acc: 12.89%\n",
      "Model parameters: epochs=35000, img_size=(32, 32), input_dim=[8] -- Train acc: 15.83% / Valid_acc: 17.34%\n",
      "Model parameters: epochs=35000, img_size=(32, 32), input_dim=[32, 8] -- Train acc: 13.14% / Valid_acc: 13.86%\n",
      "Model parameters: epochs=35000, img_size=(32, 32), input_dim=[16, 16, 8] -- Train acc: 14.57% / Valid_acc: 14.15%\n",
      "Model parameters: epochs=35000, img_size=(32, 32), input_dim=[16, 16, 32, 8] -- Train acc: 12.96% / Valid_acc: 14.63%\n",
      "Model parameters: epochs=35000, img_size=(32, 32), input_dim=[32, 32, 32, 64, 8] -- Train acc: 11.38% / Valid_acc: 12.4%\n",
      "Model parameters: epochs=35000, img_size=(64, 64), input_dim=[8] -- Train acc: 10.8% / Valid_acc: 12.11%\n"
     ]
    }
   ],
   "source": [
    "max_train_acc, max_val_acc = 0.0, 0.0\n",
    "\n",
    "for ep in EPOCHS:\n",
    "    for s in size_img:\n",
    "        IMG_SIZE = s\n",
    "        (X_train, y_train), (X_valid, y_valid) = import_dataset(IMG_SIZE=IMG_SIZE)\n",
    "        input_dim = [len(X_train[0])]\n",
    "        for n, num_h in enumerate(number_of_hidden_layers):\n",
    "            h = random.choices(hidden_layers, k=num_h)\n",
    "            if h:\n",
    "                input_dim.extend(random.choices(hidden_layers, k=num_h))\n",
    "            input_dim.append(8)\n",
    "\n",
    "            model, last_output_layer = create_mlp_model(input_dim)\n",
    "            train_classification_stochastic_gradient_backpropagation_mlp_model(model, X_train, y_train.flatten(), epochs=ep)\n",
    "\n",
    "            train_acc, valid_acc = accuracy_grid_search(model, last_output_layer, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "            if input_dim[1:-1] == []:\n",
    "                filename = f\"models/mlp/MLP_{ep}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_{input_dim[-1]}_t_acc-{train_acc}_v_acc-{valid_acc}.txt\"\n",
    "            else:\n",
    "                filename = f\"models/mlp/MLP_{ep}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_{'_'.join(map(str, input_dim[1:]))}_t_acc-{train_acc}_v_acc-{valid_acc}.txt\"\n",
    "\n",
    "            print(f\"Model parameters: epochs={ep}, img_size={IMG_SIZE}, input_dim={input_dim[1:]} -- Train acc: {train_acc}% / Valid_acc: {valid_acc}%\")\n",
    "\n",
    "            if train_acc > max_train_acc:\n",
    "                max_train_acc = train_acc\n",
    "                save_mlp_model(model, filename)\n",
    "            if valid_acc > max_val_acc:\n",
    "                max_val_acc = valid_acc\n",
    "                save_mlp_model(model, filename)\n",
    "\n",
    "            destroy_mlp_model(model)\n",
    "\n",
    "            input_dim = [len(X_train[0])]\n",
    "\n",
    "    print(f\"Max Train acc: {max_train_acc}% / Max Valid_acc: {max_val_acc}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be724982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
