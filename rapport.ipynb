{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14874ee2",
   "metadata": {},
   "source": [
    "# Rapport interactif\n",
    "\n",
    "### Sommaire\n",
    "I. Implémentation sur notre dataset\n",
    "\n",
    "II. Cas de tests\n",
    "\n",
    "### Rappel du sujet\n",
    "\n",
    "Nous essayerons de répondre à la problématique: \n",
    "- **Quel est ce monument parisien ?**\n",
    "\n",
    "À partir de notre dataset.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Nous avons utilisés une extension Chrome qui récupère entre 400 et 500 images à partir d'une recherche, puis nous avons nettoyés certaines images incohérentes. \n",
    "\n",
    "\n",
    "### Librairie\n",
    "\n",
    "Nous avons réalisé **ML**, notre propre librairie de machine learning en C++. Elle dépend de la bibliothèque **Eigen**, qui nous sert à réaliser plus facilement des calculs matriciels.\n",
    "\n",
    "### Application web\n",
    "\n",
    "Nous avons décidé de réaliser notre application web en Python en utilisant le micro-framework **Flask** ainsi que **Bootstrap** et **JQuery**\n",
    "\n",
    "### Étapes de développement\n",
    "\n",
    "1. Implémentation du perceptron\n",
    "2. Interopérabilité du perceptron\n",
    "3. Implémentation du perceptron multi-couches\n",
    "4. Interopérabilité du perceptron multi-couches\n",
    "5. Validation sur les cas de tests et correction de la librairie\n",
    "6. Rédaction de la première version du rapport pour l'étape n°2\n",
    "7. Création du site web\n",
    "8. Ajout des fonctionnalités save et load sur le percepetron\n",
    "9. Interopérabilité du save et du load sur le perceptron\n",
    "10. Ajout des fonctionnalités save et load sur le perceptron multi-couches\n",
    "11. Interopérabilité du save et du load sur le perceptron multi-couches\n",
    "12. Implémentation du Radial Basis Function Network\n",
    "13. Interopérabilité du Radial Basis Function Network\n",
    "14. Amélioration et finition du site web (*en cours*)\n",
    "15. Rédaction du rapport interactif (*en cours*)\n",
    "\n",
    "### Difficultés rencontrées\n",
    "\n",
    "- Problème d’initialisation des valeurs aléatoires, on avait des modèles tous identiques.\n",
    "- Tentative d’utiliser std::random_device pour obtenir des valeurs aléatoires plus uniformes. Cela fonctionnait mais on s’est rendus compte que rand() de stdlib suffisait pour notre besoin.\n",
    "- Confusions due au biais (on a tenté de le supprimer plusieurs fois)\n",
    "- Erreur d’allocation de mémoire entraînant des erreurs lors du passages des objets par l'interopérabilité\n",
    "- Destruction d'une instance d'un perceptron multi-couches, mal paramétré entraînant des erreurs lors de l’utilisation de l'interopérabilité.\n",
    "- Prise en main de NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdaaf91",
   "metadata": {},
   "source": [
    "# Partie 1. Implémentation sur notre dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2da79d",
   "metadata": {},
   "source": [
    "Dans cette partie, nous montrerons l'étape de pré-traitement des données (*data preprocessing*), puis nous appliquerons notre modéle linéaire ainsi que notre perceptron multi-couches à notre dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346e3e6",
   "metadata": {},
   "source": [
    "## a) Importer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from ml import *\n",
    "from rbfn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff0f6a",
   "metadata": {},
   "source": [
    "Nous définissons les constantes dont nous aurons besoin, tout au long du rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (64, 64)\n",
    "PATH = os.path.join(\"data_large/\")\n",
    "TRAIN = os.path.join(PATH, \"train\")\n",
    "classes = os.listdir(TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89634d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Les différentes classes possibles sont: {', '.join(classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056f005",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**TO-DO** : Ajouter la data augmentation dans `import_images_and_assign_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a03a28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def random_rotation(image):\n",
    "    \"\"\"\n",
    "    Random rotation of the image\n",
    "    \"\"\"\n",
    "    rand_rot = np.random.uniform(-25, 25)\n",
    "    return image.rotate(rand_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738d2d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#def random_noise(image):\n",
    "#    \"\"\"\n",
    "#    Random noise added to the image\n",
    "#    \"\"\"\n",
    "#    s = np.std(image)\n",
    "#    return image.effect_noise(IMG_SIZE, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6f9a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def horizontal_flip(image):\n",
    "    \"\"\"\n",
    "    Flip the image horizontally\n",
    "    \"\"\"\n",
    "    return image.transpose(Image.FLIP_LEFT_RIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967df66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#def blur(image):\n",
    "#    \"\"\"\n",
    "#    Blur the image\n",
    "#    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018b987",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    # \"noise\": random_noise,\n",
    "    \"rotate\": random_rotation,\n",
    "    \"flip\": horizontal_flip,\n",
    "}\n",
    "\n",
    "num_transformations_to_apply = np.random.randint(1, len(transformations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064298a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def showImg(tensor, label, prediction):\n",
    "    \"\"\"\n",
    "    Affiche une image avec sa prediction et son label\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(tensor.reshape((IMG_SIZE[0], IMG_SIZE[1], 3)))\n",
    "    ax.set_title(f'Label: {classes[np.argmax(prediction)]}')\n",
    "    ax.set_xlabel(f'Prediction: {np.argmax(prediction)} / Expected output: {np.argmax(label)}')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30be46e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def import_images_and_assign_labels(folder, label, X, Y, IMG_SIZE=IMG_SIZE, data_aug=False):\n",
    "    \"\"\"\n",
    "    Convertit et redimensionne les images d'un dossier en NumPy Array.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, file)\n",
    "        im = Image.open(image_path)\n",
    "        im = im.resize(IMG_SIZE)\n",
    "        if data_aug == True:\n",
    "            for i in range(num_transformations_to_apply):\n",
    "                k = np.random.choice(list(transformations))\n",
    "                transformed_img = transformations[k](im)\n",
    "            im = transformed_img\n",
    "        im = im.convert(\"RGB\")\n",
    "        im_arr = np.array(im)\n",
    "        im_arr = np.reshape(im_arr, (IMG_SIZE[0]* IMG_SIZE[1] * 3,))\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad12c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for s in [\"train\", \"valid\", \"test\"]:\n",
    "    if s == \"test\":\n",
    "        print(f\"Nombre d'images dans le {s} set:\")\n",
    "        print(f\"{len(os.listdir(os.path.join(PATH, s)))} images.\")\n",
    "    else:\n",
    "        print(f\"Nombre d'images par classes dans le {s} set:\")\n",
    "        res = 0\n",
    "        for cl in classes:\n",
    "            print(f\"- {cl}: {len(os.listdir(os.path.join(PATH, s, cl)))} images.\")\n",
    "            res+=len(os.listdir(os.path.join(PATH, s, cl)))\n",
    "        print(\"Total :\", res, \"images.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a78b17",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def import_dataset(IMG_SIZE=IMG_SIZE, data_aug=False):\n",
    "    \"\"\"\n",
    "    Crée les datasets d'entrainement et de validation\n",
    "    \"\"\"\n",
    "    X_train, y_train, X_valid, y_valid = [], [], [], []\n",
    "    labels = np.identity(len(os.listdir(TRAIN)))\n",
    "    for set_type in [\"train\", \"valid\"]:\n",
    "        for cl, lab in zip(classes, labels):\n",
    "            if set_type == \"train\":\n",
    "                X_set, y_set = X_train, y_train\n",
    "                import_images_and_assign_labels(\n",
    "                os.path.join(PATH, set_type, cl),\n",
    "                lab,\n",
    "                X_set,\n",
    "                y_set,\n",
    "                IMG_SIZE,\n",
    "                data_aug\n",
    "            )\n",
    "            else:\n",
    "                X_set, y_set = X_valid, y_valid\n",
    "                import_images_and_assign_labels(\n",
    "                    os.path.join(PATH, set_type, cl),\n",
    "                    lab,\n",
    "                    X_set,\n",
    "                    y_set,\n",
    "                    IMG_SIZE,\n",
    "\n",
    "                )\n",
    "\n",
    "    return (np.array(X_train) / 255.0, np.array(y_train)), \\\n",
    "           (np.array(X_valid) / 255.0, np.array(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0080101",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = import_dataset(data_aug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [\"train\", \"valid\", \"test\"]:\n",
    "    if s == \"test\":\n",
    "        print(f\"Nombre d'images dans le {s} set:\")\n",
    "        print(f\"{len(os.listdir(os.path.join(PATH, s)))} images.\")\n",
    "    else:\n",
    "        print(f\"Nombre d'images par classes dans le {s} set:\")\n",
    "        res = 0\n",
    "        for cl in classes:\n",
    "            print(f\"- {cl}: {len(os.listdir(os.path.join(PATH, s, cl)))} images.\")\n",
    "            res+=len(os.listdir(os.path.join(PATH, s, cl)))\n",
    "        print(\"Total :\", res, \"images.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_test = np.random.randint(0, len(X_valid)-1)\n",
    "print(picture_test)\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], [0, 0, 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732db63",
   "metadata": {},
   "source": [
    "## b) Appliquer le modéle linéaire au dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd76fd",
   "metadata": {},
   "source": [
    "Cette section est incomplète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ef8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model = create_linear_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_test_linear = np.random.randint(0, len(X_train))\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, X_train[picture_test_linear])\n",
    "print(\"Before training:\", test_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_linear_classification_model(p_model, input_dim, X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_after = predict_linear_model_classif(p_model, input_dim, X_train[picture_test])\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "destroy_linear_model(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69aac4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6345f8b9",
   "metadata": {},
   "source": [
    "## c) Appliquer le PMC au dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46048e",
   "metadata": {},
   "source": [
    "Nous allons créer un petit modéle contenant une seule couche cachée puis nous allons l'entraîner pour voir s'il sera capable de prédire correctement une image de la Place de la Concorde, notre image test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0043ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(classes)\n",
    "picture_test = 411\n",
    "input_dim = [len(X_train[0]), 32, NUM_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea72e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model, len_output_layer = create_mlp_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aba8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    \"\"\"\n",
    "    Evalue notre modèle sur les données d'entrainement et de validation.\n",
    "    \"\"\"\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_train)\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, NUM_CLASSES)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    print(f\"Accuracy training: {round((true_preds / total_preds) * 100, 2)}%\")\n",
    "    \n",
    "    true_preds = 0\n",
    "    total_preds = len(X_valid)\n",
    "    for x, y in zip(X_valid, y_valid):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, NUM_CLASSES)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    print(f\"Accuracy valid: {round((true_preds / total_preds) * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc63d67",
   "metadata": {},
   "source": [
    "Voyons si notre modéle non entrainé arrive à prédire correctement une image aléatoire du valid set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27645d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_before = predict_mlp_model_classification(p_model, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_before);\n",
    "\n",
    "print(\"Prediction:\", test_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cc1c1",
   "metadata": {},
   "source": [
    "Nous pouvons voir que notre modéle prédit correctement le monument environ 1 fois sur 8 (soit 12.5%). Nous avons 8 classes de monuments, ce qui veut dire que nos résultats sont totalement normaux, car notre modèle n'est pas encore entrainé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab25861",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758dfa46",
   "metadata": {},
   "source": [
    "Entraînons désormais notre modéle. Par soucis de temps, nous allons entraîner manuellement un petit modéle de 1000 époques et puis nous chargerons un gros modéle déjà entraîné par nos soins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X_train, y_train.flatten(), epochs=1000)#, alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c4966",
   "metadata": {},
   "source": [
    "Voyons si notre modéle entrainé arrive à prédire correctement une image aléatoire du valid set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_after = predict_mlp_model_classification(p_model, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_after);\n",
    "\n",
    "print(\"Prediction:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff50983",
   "metadata": {},
   "source": [
    "Prédiction **correcte** : Etait-ce un coup de chance ou notre modéle réussit désormais à distinguer les différents monuments ? \n",
    "\n",
    "Prédiction **incorrecte** : Notre modéle n'as pas réussi à prédire notre image test, as-t-il réellement appris quelque chose durant sa phase d'entraînement ? Notre modéle est potentiellement entrain de **sous-apprendre**.\n",
    "\n",
    "\n",
    "Pour en avoir le coeur net, voyons comment il s'en sort face à toutes les données du train et du valid set. Nous aurons un meilleur point de vue de son avancé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01492a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(p_model)\n",
    "destroy_mlp_model(p_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525a19e",
   "metadata": {},
   "source": [
    "Prédiction **correcte** : ^^ C'était un coup de chance, pas de bol. Le pourcentage est beaucoup trop faible, notre modéle prédit toujours l'équivalent d'une chance sur 8.\n",
    "\n",
    "Prédiction **incorrecte** : C'est tout à fait normal, notre modéle n'a pas était assez entraîné.\n",
    "\n",
    "Passons à la partie intéressante, nous allons charger un modéle pré-entrainé et nous allons effectuer le même test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87256f87",
   "metadata": {},
   "source": [
    "Pour commencer, nous allons devoir ré-importer une nouvelle fois les données mais avec une taille d'image différente, nous allons cette fois utiliser des images plus petites (8x8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fe6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = import_dataset(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224c454",
   "metadata": {},
   "source": [
    "Assurons-nous que les images soit à la bonne dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa4751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions des images applatis :\", X_train[0].shape)\n",
    "print(\"Dimensions souhaités :\", (IMG_SIZE[0]*IMG_SIZE[1]*3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78997173",
   "metadata": {},
   "source": [
    "Le prochain modéle que nous allons chargé à était entrainé 10 millions d'époques et ne contient aucune couche cachée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model2 = load_mlp_model(\"models/mlp/MLP_10000000_8x8_8_t_acc-65.5_v_acc-58.04.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31049449",
   "metadata": {},
   "source": [
    "Est-ce que le modéle entrainé 10 millions d'époques sera capable de prédire notre image selectionné aléatoirement. La suite à la prochaine cellule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load = predict_mlp_model_classification(p_model2, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_load);\n",
    "\n",
    "print(\"Prediction:\", test_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c77fb5",
   "metadata": {},
   "source": [
    "Prédiction **correcte** : FIIIOUUU ! On a pas travaillé 3 mois pour rien ;)\n",
    "\n",
    "Prédiction **incorrecte** : Voyons sur toutes les données comment notre modéle réagit. (3 mois à la poubelle )-: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118495c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(p_model2)\n",
    "destroy_mlp_model(p_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d331c1",
   "metadata": {},
   "source": [
    "On peut voir que notre modéle pré-entrainé à un peu plus de 1 chance sur 2 de prédire correctement le monument parisien sur des images qu'il n'a jamais vu.\n",
    "\n",
    "On aurait de meilleures prédictions si nous avons un modéle soit plus gros, soit plus entrainé. Essayons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550aecf",
   "metadata": {},
   "source": [
    "Le prochain modéle que nous allons chargé à était entrainé 15 millions d'époques et ne contient 3 couches cachées (16, 8, 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_model3 = load_mlp_model(\"models/mlp/overfit/MLP_15000000_16x16_16_8_8_8_t_acc-80.6_v_acc-57.27.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086da51",
   "metadata": {},
   "source": [
    "Est-ce que le modéle entrainé 15 millions d'époques sera capable de prédire notre image selectionné aléatoirement. La suite à la prochaine cellule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575fe015",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p3 = predict_mlp_model_classification(p_model3, X_valid[picture_test], input_dim[-1])\n",
    "\n",
    "showImg(X_valid[picture_test], y_valid[picture_test], test_p3);\n",
    "\n",
    "print(\"Prediction:\", test_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cd1922",
   "metadata": {},
   "source": [
    "Réponse logique, oui. Maintenant, voyons sur toutes les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d81dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(p_model3)\n",
    "destroy_mlp_model(p_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005d02a",
   "metadata": {},
   "source": [
    "Aïe, notre modéle a sur-appris. :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c92ac",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba37735",
   "metadata": {},
   "source": [
    "## d) Découverte de nouveaux modéles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5316d9",
   "metadata": {},
   "source": [
    "Pour faciliter notre recherche d'architectures, nous avons décidé de créer un équivalent au **GridSearch** de Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779251c",
   "metadata": {},
   "source": [
    "On insére les hyperparametres que l'on souhaite essayer sur notre modéle à la prochaine cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_layers = [0, 1, 2, 3]\n",
    "hidden_layers = [8, 16, 32, 64]\n",
    "size_img = [(8, 8), (16, 16), (32, 32)]\n",
    "EPOCHS = [100, 200]\n",
    "alphas = [1e-2, 1e-3, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c294429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_for_grid_search(model, len_output, X_tr, y_tr, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Evalue notre modéle sur les données d'entrainement et de validation.\n",
    "    \"\"\"\n",
    "    train_total, valid_total = len(X_train), len(X_valid)\n",
    "    true_preds = 0\n",
    "    total_preds = len(X_tr)\n",
    "    for x, y in zip(X_tr, y_tr):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    train_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    true_preds = 0\n",
    "    total_preds = len(X_val)\n",
    "    for x, y in zip(X_val, y_val):\n",
    "        if np.argmax(predict_mlp_model_classification(model, x, len_output)) == np.argmax(y):\n",
    "            true_preds += 1\n",
    "    valid_acc = round((true_preds / total_preds) * 100, 2)\n",
    "    \n",
    "    return train_acc, valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67b997",
   "metadata": {},
   "source": [
    "Notre fonction `grid_search()` a pour but de trouver le modéle qui a les meilleures résultats de prédictions et de les enregistrer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f83eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(epochs=EPOCHS, size_img=size_img, hidden_layers=hidden_layers, number_of_hidden_layers=number_of_hidden_layers):\n",
    "    \"\"\"\n",
    "    Equivalent au Grid Search de Sklearn.\n",
    "    \"\"\"\n",
    "    max_train_acc, max_val_acc = 0.0, 0.0\n",
    "\n",
    "    for ep in EPOCHS:\n",
    "        for s in size_img:\n",
    "            IMG_SIZE = s\n",
    "            (X_train, y_train), (X_valid, y_valid) = import_dataset(IMG_SIZE=IMG_SIZE, data_aug=True)\n",
    "            input_dim = [len(X_train[0])]\n",
    "            for al in alphas:\n",
    "                for n, num_h in enumerate(number_of_hidden_layers):\n",
    "                    h = random.choices(hidden_layers, k=num_h)\n",
    "                    if h:\n",
    "                        input_dim.extend(random.choices(hidden_layers, k=num_h))\n",
    "                    input_dim.append(NUM_CLASSES)\n",
    "\n",
    "                    model, last_output_layer = create_mlp_model(input_dim)\n",
    "                    \n",
    "                    for _ in range(ep):\n",
    "                        train_classification_stochastic_gradient_backpropagation_mlp_model(model, X_train, y_train.flatten(), epochs=len(X_train), alpha=al)\n",
    "\n",
    "                    train_acc, valid_acc = accuracy_for_grid_search(model, last_output_layer, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "                    if input_dim[1:-1] == []:\n",
    "                        filename = f\"models/mlp/MLP_{ep}_{al}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_{input_dim[-1]}_t_acc-{train_acc}_v_acc-{valid_acc}.txt\"\n",
    "                    else:\n",
    "                        filename = f\"models/mlp/MLP_{ep}_{al}_{IMG_SIZE[0]}x{IMG_SIZE[1]}_{'_'.join(map(str, input_dim[1:]))}_t_acc-{train_acc}_v_acc-{valid_acc}.txt\"\n",
    "\n",
    "                    print(f\"Params ~ epochs={ep},alpha={al},img_size={IMG_SIZE},input_dim={input_dim[1:]} ~ t_acc: {train_acc}% / v_acc: {valid_acc}%\")\n",
    "\n",
    "                    if train_acc > max_train_acc:\n",
    "                        max_train_acc = train_acc\n",
    "                        #save_mlp_model(model, filename)\n",
    "                    if valid_acc > max_val_acc:\n",
    "                        max_val_acc = valid_acc\n",
    "                        #save_mlp_model(model, filename)\n",
    "\n",
    "                    destroy_mlp_model(model)\n",
    "\n",
    "                    input_dim = [len(X_train[0])]\n",
    "\n",
    "        print(f\"Max Train acc: {max_train_acc}% / Max Valid_acc: {max_val_acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2e8e6",
   "metadata": {},
   "source": [
    "C'est parti, on lance la recherche d'architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80793910",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a787eb9b",
   "metadata": {},
   "source": [
    "Cette fonction nous a permis d'essayer toutes les possibilités des **hyperparametres** de manière automatisé, de pouvoir entraîner plusieurs **modèles** toute une nuit et d'obtenir une sorte de recap à la fin du grid search.\n",
    "\n",
    "Nous avons essayer tout un panel de taille d'image allant de 6x6 à 64x64, un nombre de couches cachées allant de 0 à 4, des nombres de noeuds par couche entre 4 et 1024 et enfin un nombre d'époques de 1000 allant jusqu'à 20M.\n",
    "\n",
    "Aujourd'hui, à notre grande surprise, nous avons découvert que pour notre problématique, les modéles sans couches cachées et avec une petite taille d'images prédisent mieux que de **grand/gros** modéles avec une grande taille d'images. \n",
    "\n",
    "En plus de leur taille, les grand modéles prennent plus de temps à s'entraîner.\n",
    "\n",
    "Nos modéles qui généralisent le mieux ont un taux de réussite d'environ 65% de précision sur des données inconnues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fa786",
   "metadata": {},
   "source": [
    "## e) Les courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc951322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningPlot:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def display(self, **params):\n",
    "        if self.model_name.lower() == \"mlp\":\n",
    "            input_dim = params.get(\"input_dim\")\n",
    "            epochs = params.get(\"epochs\")\n",
    "            alpha = params.get(\"alpha\")\n",
    "            self.display_mlp_curves(input_dim, epochs, alpha)\n",
    "        elif self.model_name.lower() == \"perceptron\":\n",
    "            # TODO\n",
    "            ...\n",
    "        elif self.model_name.lower() == \"rbf\":\n",
    "            input_dim = params.get(\"input_dim\")\n",
    "            epochs = params.get(\"epochs\")\n",
    "            num_classes = params.get(\"num_classes\")\n",
    "            k = params.get(\"k\")\n",
    "            self.display_rbf_curves(input_dim, num_classes, k, epochs)\n",
    "        else:\n",
    "            print(f\"Le modèle {self.model_name} n'existe pas !\")\n",
    "            raise ArgumentError\n",
    "            \n",
    "    \n",
    "    def display_rbf_curves(self, input_dim, num_classes, k, epochs):\n",
    "        # TODO : NOT WORKING YET\n",
    "        \n",
    "        losses, val_losses, accs, val_accs = [], [], [], []\n",
    "        \n",
    "        model = create_rbfn_model(input_dim, num_classes, k)\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            train_rbfn_model(model, X_train, y_train.flatten())\n",
    "\n",
    "            y_preds = []\n",
    "            y_true = []\n",
    "            y_true_l = []\n",
    "            y_preds_l = []\n",
    "\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                preds = predict_rbfn(model, x)\n",
    "                y_preds_l.append(preds)\n",
    "                y_preds.append(np.argmax(preds))\n",
    "                y_true_l.append(y)\n",
    "                y_true.append(np.argmax(y))\n",
    "            loss = CategoricalCrossentropy()\n",
    "            losses.append(loss(y_true_l, y_preds_l))    \n",
    "            accs.append(accuracy_score(y_true, y_preds))\n",
    "\n",
    "            y_preds = []\n",
    "            y_true = []\n",
    "            y_true_l = []\n",
    "            y_preds_l = []\n",
    "\n",
    "            for x, y in zip(X_valid, y_valid):\n",
    "                preds = predict_rbfn(model, x)\n",
    "                y_preds_l.append(preds)\n",
    "                y_preds.append(np.argmax(preds))\n",
    "                y_true_l.append(y)\n",
    "                y_true.append(np.argmax(y))\n",
    "            val_losses.append(loss(y_true_l, y_preds_l))    \n",
    "            val_accs.append(accuracy_score(y_true, y_preds))\n",
    "\n",
    "            clear_output(True)\n",
    "\n",
    "            plt.plot(losses)\n",
    "            plt.plot(val_losses)\n",
    "            plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "            plt.title('Evolution of loss (CCE)')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.ylabel(f'categorical cross-entropy (softmax loss)')\n",
    "            plt.show() \n",
    "\n",
    "            plt.plot(accs)\n",
    "            plt.plot(val_accs)\n",
    "            plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "            plt.title('Evolution of accuracy')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.ylabel(f'Accuracy (%)')\n",
    "            plt.show()\n",
    "        \n",
    "    \n",
    "    def display_mlp_curves(self, input_dim, epochs, alpha):\n",
    "        losses, val_losses, accs, val_accs = [], [], [], []\n",
    "        model, last_output_layer = create_mlp_model(input_dim)\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            train_classification_stochastic_gradient_backpropagation_mlp_model(model, X_train, y_train.flatten(), epochs=len(X_train))\n",
    "\n",
    "            y_preds = []\n",
    "            y_true = []\n",
    "            y_true_l = []\n",
    "            y_preds_l = []\n",
    "\n",
    "            for x, y in zip(X_train, y_train):\n",
    "                preds = predict_mlp_model_classification(model, x, input_dim[-1])\n",
    "                y_preds_l.append(preds)\n",
    "                y_preds.append(np.argmax(preds))\n",
    "                y_true_l.append(y)\n",
    "                y_true.append(np.argmax(y))\n",
    "            loss = CategoricalCrossentropy()\n",
    "            losses.append(loss(y_true_l, y_preds_l))    \n",
    "            accs.append(accuracy_score(y_true, y_preds))\n",
    "\n",
    "            y_preds = []\n",
    "            y_true = []\n",
    "            y_true_l = []\n",
    "            y_preds_l = []\n",
    "\n",
    "            for x, y in zip(X_valid, y_valid):\n",
    "                preds = predict_mlp_model_classification(model, x, input_dim[-1])\n",
    "                y_preds_l.append(preds)\n",
    "                y_preds.append(np.argmax(preds))\n",
    "                y_true_l.append(y)\n",
    "                y_true.append(np.argmax(y))\n",
    "            val_losses.append(loss(y_true_l, y_preds_l))    \n",
    "            val_accs.append(accuracy_score(y_true, y_preds))\n",
    "\n",
    "            clear_output(True)\n",
    "\n",
    "            plt.plot(losses)\n",
    "            plt.plot(val_losses)\n",
    "            plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "            plt.title('Evolution of loss (CCE)')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.ylabel(f'categorical cross-entropy (softmax loss)')\n",
    "            plt.show() \n",
    "\n",
    "            plt.plot(accs)\n",
    "            plt.plot(val_accs)\n",
    "            plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "            plt.title('Evolution of accuracy')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.ylabel(f'Accuracy (%)')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LearningPlot(\"MLP\")\n",
    "m.display(input_dim=[len(X_train[0]), 64, 32, NUM_CLASSES], epochs=40, alpha=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "r = LearningPlot(\"RBF\")\n",
    "r.display(input_dim=len(X_train[0]), epochs=40, num_classes=NUM_CLASSES, k=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905665a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b5695",
   "metadata": {},
   "source": [
    "# Partie 2. Cas de tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a738c2d",
   "metadata": {},
   "source": [
    "Avant de démarrer notre recherche d'architecture viable pour nos modèles, il a fallu s'assurer que les algorithmes de notre lib étaient corrects. Pour cela, nous avons utilisé des jeux de données où les résultats sont visuellement interprétables, ou bien dont les prédictions peuvent être calculées à la main sans y passer 4heures. L'idéal était donc de travailler sur des points en 2D ou 3D, avec une quantité limitée de point. Si nos modèles permettent de classifier nos points correctement, on pourra ensuite passer à de plus gros volumes de données, dans des dimensions impossible à interpréter pour l'Humain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9579006",
   "metadata": {
    "id": "_qYwTgKqxnkl"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0702a",
   "metadata": {
    "id": "-d0zULTsyFhh"
   },
   "source": [
    "### Linear Simple :\n",
    "        Linear Model : OK\n",
    "        MLP (2, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5e15b",
   "metadata": {
    "id": "EktwRhEMxV2A"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [2.5, 4],\n",
    "      [2, 3],\n",
    "      [3, 3]\n",
    "])\n",
    "Y = np.array([\n",
    "      1,\n",
    "      -1,\n",
    "      -1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2da2c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "OpWOCJ5ZyDMY",
    "outputId": "25884536-e733-4cee-b175-79c147b7c927"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[0, 0], X[0, 1], color='blue')\n",
    "plt.scatter(X[1:3,0], X[1:3,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim = len(X[0])\n",
    "\n",
    "errors = 0\n",
    "\n",
    "for _ in range(50):\n",
    "    test_after = []\n",
    "    p_model = create_linear_model(model_dim)\n",
    "\n",
    "    train_linear_classification_model(p_model, model_dim, X, Y, alpha=0.001, epochs=10_000)\n",
    "\n",
    "    for data, expected in zip(X, Y):\n",
    "        out = predict_linear_model_classif(p_model, model_dim, data)\n",
    "        test_after.append(out)\n",
    "        if out != expected:\n",
    "            errors += 1\n",
    "    print(test_after)\n",
    "    destroy_linear_model(p_model)\n",
    "\n",
    "print(f\"errors: {errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfd32b",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, [1, 1])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y, alpha=0.001, epochs=10000)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [1, 1])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f1f02",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_linear_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 5, 0.5) for x2 in np.arange(-1, 5, 0.5)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model, input_dim,  p) for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_linear_classification_model(model, input_dim, flattened_dataset_inputs, Y, epochs=10000)\n",
    "\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model,input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim, [1, 1])\n",
    "\n",
    "print(\"Prediction after training of [1, 1], the prediction need to be equal to 1. \\nPrediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fab88",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7891e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "p_model, _= create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36986aa1",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8112c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 5, 0.5) for x2 in np.arange(-1, 5, 0.5)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model , [1, 1])\n",
    "\n",
    "print(\"Prediction after training of [1, 1], the result need to be equal to 1. Result:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f8094",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb14726",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 2\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if label >= 0 else [0,1] for label in Y]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, X, expected_output)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = [[x,y] for x in range(6) for y in range(6)]\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b957dee",
   "metadata": {
    "id": "7v8KFue-zmCv"
   },
   "source": [
    "### Linear Multiple :\n",
    "        Linear Model : OK\n",
    "        MLP (2, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6d693",
   "metadata": {
    "id": "hZlnpb-qzmCw"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate([np.random.random((50,2)) * 0.9 + np.array([1, 1]), np.random.random((50,2)) * 0.9 + np.array([2, 2])])\n",
    "Y = np.concatenate([np.ones((50, 1)), np.ones((50, 1)) * -1.0])\n",
    "plt.scatter(X[0:50, 0], X[0:50, 1], color='blue')\n",
    "plt.scatter(X[50:100,0], X[50:100,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c8db3",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aeeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, [1.25, 1.25])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [1.25, 1.25])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9ba94",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f62770",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_linear_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(1, 3, 0.1) for x2 in np.arange(1, 3, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "    #print(flattened_dataset_inputs)\n",
    "\n",
    "train_linear_classification_model(model, input_dim, X, Y, epochs=100000)\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model,input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [2.5, 2.5])\n",
    "\n",
    "print(\"Prediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d08eda",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "p_model, _ = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [1.25, 1.25])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1.25, 1.25])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12007487",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7077e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _= create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(1, 3, 0.1) for x2 in np.arange(1, 3, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y, epochs=100000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model , [1, 1])\n",
    "\n",
    "print(\"Prediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a0049",
   "metadata": {},
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dd911",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 20\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if label >= 0 else [0,1] for label in Y]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, X, expected_output)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = [[x/10,y/10] for x in range(51) for y in range(51)]\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1adb09",
   "metadata": {
    "id": "gZlONmsp1T_W"
   },
   "source": [
    "### XOR :\n",
    "        Linear Model    : KO\n",
    "        MLP (2, 2, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb9b8e",
   "metadata": {
    "id": "673wfC9U1T_W"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]])\n",
    "Y = np.array([1, 1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aa1f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "uA3E-h801T_Y",
    "outputId": "9fc31c6d-e44c-447b-a7c0-a3fa7b0d778e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[0:2, 0], X[0:2, 1], color='blue')\n",
    "plt.scatter(X[2:4,0], X[2:4,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd262d4",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "On isole les 4 points par 2 sorties de\n",
    "modèle linéaire, chacune entraînée par 2 valeurs d’une classe et 1 valeur de\n",
    "l’autre classe. On simule en réalité le travail d’un MLP (2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75abf7",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd76f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "Y = np.array([-1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aae1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model_top = create_linear_model(input_dim)\n",
    "model_bottom = create_linear_model(input_dim)\n",
    "\n",
    "\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 2, 0.1) for x2 in np.arange(-1, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs_top = [predict_linear_model_classif(model_top, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_bottom = [predict_linear_model_classif(model_bottom, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if top == 1 and bottom == 1 else 'red' for (top, bottom) in zip(predicted_outputs_top, predicted_outputs_bottom)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "train_linear_classification_model(model_top, input_dim, X[:-1], Y[:-1], alpha=0.01, epochs=100000)\n",
    "train_linear_classification_model(model_bottom, input_dim, X[1:], Y[1:], alpha=0.01, epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs_top = [predict_linear_model_classif(model_top, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_bottom = [predict_linear_model_classif(model_bottom, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if top == 1 and bottom == 1 else 'red' for (top, bottom) in zip(predicted_outputs_top, predicted_outputs_bottom)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "destroy_linear_model(model_top)\n",
    "destroy_linear_model(model_bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9b1aa",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0]), 1]\n",
    "\n",
    "p_model, _= create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a094c",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1, 2, 0.1) for x2 in np.arange(-1, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y, epochs=100000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [1, 1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7efe87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 4\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if label >= 0 else [0,1] for label in Y]\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, X, expected_output, naif=True)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = [[x/5,y/5] for x in range(6) for y in range(6)]\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e6c5d",
   "metadata": {
    "id": "5qxkXVo02MpM"
   },
   "source": [
    "### Cross :\n",
    "        Linear Model    : KO\n",
    "        MLP (2, 4, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487c399",
   "metadata": {
    "id": "7kkrrfnX2MpM"
   },
   "outputs": [],
   "source": [
    "X = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "Y = np.array([1 if abs(p[0]) <= 0.3 or abs(p[1]) <= 0.3 else -1 for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef933068",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "zVBAE2fY2MpO",
    "outputId": "46b434a6-2fd8-492e-c080-14b0d0028968"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == 1, enumerate(X)))))[:,1], color='blue')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == -1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]] == -1, enumerate(X)))))[:,1], color='red')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5945a89",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "On génère plusieurs modèles linéaires\n",
    "qui vont découper la croix en différentes parties pour isoler 1 à 1 les blocs\n",
    "rouges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, Y)\n",
    "\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [0, 0])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0913307f",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model_vl = create_linear_model(input_dim)\n",
    "model_vr = create_linear_model(input_dim)\n",
    "model_ht = create_linear_model(input_dim)\n",
    "model_hb = create_linear_model(input_dim)\n",
    "\n",
    "\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-2, 2, 0.1) for x2 in np.arange(-2, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs_vl = [predict_linear_model_classif(model_vl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_vr = [predict_linear_model_classif(model_vr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_ht = [predict_linear_model_classif(model_ht, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_hb = [predict_linear_model_classif(model_hb, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if (vl == 1 and vr == 1) or (ht == 1 and hb == 1) else 'red' for (vl, vr, ht, hb) in zip(predicted_outputs_vl, predicted_outputs_vr, predicted_outputs_ht, predicted_outputs_hb)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ht = np.array([[x[0],x[1],n] for n,x in enumerate(X) if (x[1] > -0.3 and (x[0] > 0.3 or x[0] < -0.3) ) ])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in ht[:, 2]]\n",
    "plt.scatter(ht[:, 0], ht[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Horizontal top\")\n",
    "plt.show()\n",
    "\n",
    "vr = np.array([[x[0],x[1], int(n)] for n,x in enumerate(X) if x[0] > -0.3 and (x[1] > 0.3 or x[1] < -0.3) ])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in vr[:, 2]]\n",
    "plt.scatter(vr[:, 0], vr[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Vertical right\")\n",
    "plt.show()\n",
    "\n",
    "vl = np.array([[x[0],x[1],int(n)] for n,x in enumerate(X) if (x[0] < 0.3 and (x[1] < -0.3 or x[1] > 0.3))])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in vl[:, 2]]\n",
    "plt.scatter(vl[:, 0], vl[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Vertical left\")\n",
    "plt.show()\n",
    "\n",
    "hb = np.array([[x[0],x[1],int(n)] for n,x in enumerate(X) if (x[1] < 0.3 and (x[0] < -0.3 or x[0] > 0.3))])\n",
    "c = [\"blue\" if Y[int(n)] == 1 else \"red\" for n in hb[:, 2]]\n",
    "plt.scatter(hb[:, 0], hb[:, 1], c=c)\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.title(\"Horizontal bottom\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# On était bloqué la wola\n",
    "train_linear_classification_model(model_vl, input_dim, vl[:, :-1], Y[vl[:,-1].astype(int)], epochs=100000)\n",
    "train_linear_classification_model(model_vr, input_dim, vr[:, :-1], Y[vr[:,-1].astype(int)], epochs=100000)\n",
    "train_linear_classification_model(model_ht, input_dim, ht[:, :-1], Y[ht[:,-1].astype(int)], epochs=100000)\n",
    "train_linear_classification_model(model_hb, input_dim, hb[:, :-1], Y[hb[:,-1].astype(int)], epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs_vl = [predict_linear_model_classif(model_vl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_vr = [predict_linear_model_classif(model_vr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_ht = [predict_linear_model_classif(model_ht, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_hb = [predict_linear_model_classif(model_hb, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['blue' if (vl == 1 and vr == 1) or (ht == 1 and hb == 1) else 'red' for (vl, vr, ht, hb) in zip(predicted_outputs_vl, predicted_outputs_vr, predicted_outputs_ht, predicted_outputs_hb)]\n",
    "\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "destroy_linear_model(model_vl)\n",
    "destroy_linear_model(model_vr)\n",
    "destroy_linear_model(model_ht)\n",
    "destroy_linear_model(model_hb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333c1c0",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a108d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0])*2, 1]\n",
    "\n",
    "p_model, _ = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [0, 0])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [0, 0])\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069f9931",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8461815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-2, 2, 0.1) for x2 in np.arange(-2, 2, 0.1)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y, alpha=0.01, epochs=200000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label[0] >= 0 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model , [1, 1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cefa9",
   "metadata": {},
   "source": [
    "### RBFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f1cde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "k = 30\n",
    "input_dim = 2\n",
    "expected_output = [[1,0] if coord >= 0 else [0,1] for coord in Y]\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output)\n",
    "\n",
    "colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] else 'red' for predict in [predict_rbfn(model, coord) for coord in plot_input]]\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0533d",
   "metadata": {
    "id": "v4hhnYge928d"
   },
   "source": [
    "### Multi Linear 3 classes :\n",
    "        Linear Model x3 : OK\n",
    "        MLP (2, 3)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303bffc1",
   "metadata": {
    "id": "IvhvqkDw928q"
   },
   "outputs": [],
   "source": [
    "X = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "Y = np.array([[1, 0, 0] if -p[0] - p[1] - 0.5 > 0 and p[1] < 0 and p[0] - p[1] - 0.5 < 0 else # bleu\n",
    "              [0, 1, 0] if -p[0] - p[1] - 0.5 < 0 and p[1] > 0 and p[0] - p[1] - 0.5 < 0 else # rouge\n",
    "              [0, 0, 1] if -p[0] - p[1] - 0.5 < 0 and p[1] < 0 and p[0] - p[1] - 0.5 > 0 else # vert\n",
    "              [0, 0, 0]for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1ef9f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "4aqzcUlJ928s",
    "outputId": "71df307b-e9c9-4a2d-a942-b75e3a141e46"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,1], color='blue')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,1], color='red')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,1], color='green')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e96eb5",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b54605",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim, [-0.75, -0.50])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "flattened_Y = Y[-1].flatten()\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, X, flattened_Y)\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim, [-0.75, -0.50])\n",
    "\n",
    "print(\"After training:\",test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91200b9f",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a27b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "\n",
    "model_dr = create_linear_model(input_dim)\n",
    "model_dl = create_linear_model(input_dim)\n",
    "model_h = create_linear_model(input_dim)\n",
    "\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1.5, 1.5, 0.1) for x2 in np.arange(-1.5, 1.5, 0.1)]\n",
    "colors = [\"blue\" if output[0] == 1 else (\"red\" if output[1] == 1 else (\"green\" if output[2] == 1 else \"black\")) for output in Y]\n",
    "\n",
    "dr = np.array([1 if y[2] == 1 else -1 for y in Y])\n",
    "h = np.array([1 if y[1] == 1 else -1 for y in Y])\n",
    "dl = np.array([1 if y[0] == 1 else -1 for y in Y])\n",
    "\n",
    "predicted_outputs_dr = [predict_linear_model_classif(model_dr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_dl = [predict_linear_model_classif(model_dl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_h = [predict_linear_model_classif(model_h, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "\n",
    "predicted_outputs_colors = ['green' if (dr == 1 and dl == -1 and h == -1) else (\"blue\" if (dl == 1 and dr == -1 and h == -1) else (\"red\" if (h == 1 and dr == -1 and dl == -1) else \"black\")) for (dr, dl, h) in zip(predicted_outputs_dr, predicted_outputs_dl, predicted_outputs_h)]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=40)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "flattened_dataset_outputs = []\n",
    "for p in Y:\n",
    "    flattened_dataset_outputs.append(p[0])\n",
    "    flattened_dataset_outputs.append(p[1])\n",
    "    flattened_dataset_outputs.append(p[2])\n",
    "    \n",
    "\n",
    "train_linear_classification_model(model_dl, input_dim, X, dl, alpha=0.01, epochs=100000)\n",
    "train_linear_classification_model(model_dr, input_dim, X, dr, alpha=0.01, epochs=100000)\n",
    "train_linear_classification_model(model_h, input_dim, X, h, alpha=0.01, epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs_dr = [predict_linear_model_classif(model_dr, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_dl = [predict_linear_model_classif(model_dl, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_h = [predict_linear_model_classif(model_h, input_dim,  p)  for p in test_dataset]\n",
    "\n",
    "predicted_outputs_colors = ['green' if (dr == 1 and dl == -1 and h == -1) else (\"blue\" if (dl == 1 and dr == -1 and h == -1) else (\"red\" if (h == 1 and dr == -1 and dl == -1) else \"black\")) for (dr, dl, h) in zip(predicted_outputs_dr, predicted_outputs_dl, predicted_outputs_h)]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0aaa73",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 3]\n",
    "\n",
    "p_model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, np.array([-0.75, -0.50]), len_output_layer)\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y.flatten())\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, np.array([-0.75, -0.50]), len_output_layer)\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246d1cd",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ffebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 3]\n",
    "\n",
    "model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-1.5, 1.6, 0.2) for x2 in np.arange(-1.5, 1.6, 0.2)]\n",
    "colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=50)\n",
    "plt.show()\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y.flatten())\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=50)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b407155",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41637bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "k = 30\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output)\n",
    "\n",
    "#colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] and predict[0] > predict[2] else ('red' if predict[1] > predict[2] else 'green') for predict in [predict_rbfn(model, coord, 3) for coord in plot_input]]\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e51a12",
   "metadata": {
    "id": "uKFBx2m066i2"
   },
   "source": [
    "### Multi Cross :\n",
    "        Linear Model x3 : KO\n",
    "        MLP (2, ?, ?, 3): OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71dad19",
   "metadata": {
    "id": "0ZE8OW-K66i5"
   },
   "outputs": [],
   "source": [
    "X = np.random.random((1000, 2)) * 2.0 - 1.0\n",
    "Y = np.array([[1, 0, 0] if abs(p[0] % 0.5) <= 0.25 and abs(p[1] % 0.5) > 0.25 else [0, 1, 0] if abs(p[0] % 0.5) > 0.25 and abs(p[1] % 0.5) <= 0.25 else [0, 0, 1] for p in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa1642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "55U95UMS66i6",
    "outputId": "f14df72f-c2c1-4498-9668-f91f29594b06"
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][0] == 1, enumerate(X)))))[:,1], color='blue')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][1] == 1, enumerate(X)))))[:,1], color='red')\n",
    "plt.scatter(np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,0], np.array(list(map(lambda elt : elt[1], filter(lambda c: Y[c[0]][2] == 1, enumerate(X)))))[:,1], color='green')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6647bc7",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "Impossible de classer tous ces groupes\n",
    "avec uniquement 3 “droites”, on a alors transformé les entrées de notre\n",
    "modèle pour n’avoir qu’une instance des quatre groupes qui se répétaient à\n",
    "l’infini sur l’ensemble d’origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc27e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_dim = len(X[0])\n",
    "\n",
    "p_model = create_linear_model(input_dim)\n",
    "test_before = predict_linear_model_classif(p_model, input_dim , [2, 2])\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "flattened_X = X.flatten()\n",
    "\n",
    "train_linear_classification_model(p_model, input_dim, flattened_X, Y)\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [2, 2])\n",
    "\n",
    "print(\"After training:\",test_after)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0b8db",
   "metadata": {},
   "source": [
    "### Linear model (advanced)\n",
    "\n",
    "Ne fonctionne pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6feed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = create_linear_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in range(1, 2) for x2 in range(1, 2)]\n",
    "colors = [\"blue\" if output >= 0 else \"red\" for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model, input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "train_linear_classification_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = [predict_linear_model_classif(model,input_dim,  p)  for p in test_dataset]\n",
    "predicted_outputs_colors = ['blue' if label == 1 else 'red' for label in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.show()\n",
    "\n",
    "test_after = predict_linear_model_classif(p_model, input_dim , [1.25, 1.25])\n",
    "\n",
    "print(\"Prediction:\", test_after)\n",
    "\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "    flattened_dataset_inputs.append(p[1])\n",
    "\n",
    "destroy_linear_model(model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e9529",
   "metadata": {},
   "source": [
    "### MLP (simple)\n",
    "\n",
    "Nous avons cherché à augmenter le nombre de\n",
    "neurones par couche jusqu’à ne plus observer qu’une stagnation des\n",
    "performances de traitement contre un temps de traitement croissant. On a\n",
    "considéré qu’une forme de (2,64,64,3) était un bon compromis\n",
    "performances/rapidité. Il a cependant fallu travailler sur le nombre\n",
    "d'époques ainsi que sur la correction apportée à chaque époque pour\n",
    "favoriser l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebe3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]),2,2,3]\n",
    "\n",
    "p_model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_before = predict_mlp_model_classification(p_model, [2.5, 2.5], len_output_layer)\n",
    "\n",
    "print(\"Before training:\", test_before)\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(p_model, X, Y.flatten(), epochs=10000)\n",
    "\n",
    "test_after = predict_mlp_model_classification(p_model, [2.5, 2.5], len_output_layer)\n",
    "\n",
    "print(\"After training:\", test_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83cfba",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]),26,26,3]\n",
    "\n",
    "\n",
    "model, len_output_layer = create_mlp_model(input_dim)\n",
    "test_dataset = [[x1, x2] for x1 in np.arange(-2, 2,0.1) for x2 in np.arange(-2, 2, 0.1)]\n",
    "colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in Y]\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_classification_stochastic_gradient_backpropagation_mlp_model(model, X, Y.flatten(), alpha=0.03, epochs=1000000)\n",
    "\n",
    "predicted_outputs = [predict_mlp_model_classification(model, p, len_output_layer)  for p in test_dataset]\n",
    "predicted_outputs_colors = [\"blue\" if np.argmax(output) == 0 else (\"red\" if np.argmax(output) == 1 else \"green\") for output in predicted_outputs]\n",
    "plt.scatter([p[0] for p in test_dataset], [p[1] for p in test_dataset], c=predicted_outputs_colors)\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41251b16",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86363c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "k = 100\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = [[coord[0],coord[1]] for coord in X]\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output)\n",
    "\n",
    "#colors = ['blue' if coord >= 0 else 'red' for coord in Y]\n",
    "plot_input = np.random.random((1000, 2)) * 2.0 - 1.0\n",
    "plot_output_colors = ['blue' if predict[0] > predict[1] and predict[0] > predict[2] else ('red' if predict[1] > predict[2] else 'green') for predict in [predict_rbfn(model, coord, 3) for coord in plot_input]]\n",
    "#plt.scatter([p[0] for p in X], [p[1] for p in X], c=colors, s=200)\n",
    "plt.scatter([p[0] for p in plot_input], [p[1] for p in plot_input], c=plot_output_colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9961ee",
   "metadata": {
    "id": "zyrivJMK_WOQ"
   },
   "source": [
    "## Régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78a949",
   "metadata": {
    "id": "p4EB787A_WOR"
   },
   "source": [
    "### Linear Simple 2D :\n",
    "        Linear Model : OK\n",
    "        MLP (1, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525ad99",
   "metadata": {
    "id": "dan93I7A_WOR"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1],\n",
    "      [2]\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744654b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "6vHbCksm_sQU",
    "outputId": "1e476e34-d3ef-456a-c46e-62de28756946"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ea359",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0f75c9",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 5, 0, 5])\n",
    "plt.show()\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 5, 0, 5])\n",
    "plt.show()\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c614a8",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 1])    \n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y)\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bdd90",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 1])    \n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([-10, 10, -10, 10])\n",
    "plt.show()\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([-10, 10, -10, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80113f9",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 2\n",
    "input_dim = 1\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.random.random((100, 1)) * 4.0\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, 1) for coord in plot_input]]\n",
    "plt.scatter(plot_input, plot_output_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeecfd9",
   "metadata": {
    "id": "CkFb79fq_6ci"
   },
   "source": [
    "### Non Linear Simple 2D :\n",
    "        Linear Model    : OK\n",
    "        MLP (1, ?, 1)   : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a748e0",
   "metadata": {
    "id": "sZqi1Yy3_6cj"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1],\n",
    "      [2],\n",
    "      [3]\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      3,\n",
    "      2.5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08b270b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "NSqXDh6c_6ck",
    "outputId": "5e07562b-4b2f-4dc9-b4bd-263ac1b778fd"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X,Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e6ba6",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [3])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f07fe",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4961344",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "flattened_dataset_inputs = []\n",
    "for p in X:\n",
    "    flattened_dataset_inputs.append(p[0])\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 4, 0, 4])\n",
    "plt.show()\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(0, 6)]\n",
    "predicted_outputs = [predict_linear_model_regression(model, input_dim, [p])  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0, 4, 0, 4])\n",
    "plt.show()\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4e5ae",
   "metadata": {},
   "source": [
    "### MLP (simple)\n",
    "\n",
    "On a décidé de mettre 1 couche cachée\n",
    "de 2 neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 1, 1])    \n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y)\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [3])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3114191",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec38368",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = create_mlp_model([1, 2, 1])    \n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0,4,0,4])\n",
    "plt.show()\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               epochs=1000000)\n",
    "\n",
    "test_dataset_inputs = [i for i in range(-10, 11)]\n",
    "predicted_outputs = [predict_mlp_model_regression(model, [p])[0]  for p in test_dataset_inputs]\n",
    "\n",
    "plt.plot(test_dataset_inputs, predicted_outputs)\n",
    "plt.scatter([p[0] for p in X], Y, s=200)\n",
    "plt.axis([0,4,0,4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318044c3",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c00d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 3\n",
    "input_dim = 1\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.random.random((100, 1)) * 4.0\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, 1) for coord in plot_input]]\n",
    "plt.scatter(plot_input, plot_output_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6cd32a",
   "metadata": {
    "id": "WT1s5lZxAJuL"
   },
   "source": [
    "### Linear Simple 3D :\n",
    "        Linear Model    : OK\n",
    "        MLP (2, 1)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe9f40",
   "metadata": {
    "id": "KL_IanGMAJuM"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1, 1],\n",
    "      [2, 2],\n",
    "      [6, 1]\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      3,\n",
    "      5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4070fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "91dQpMIzAJuO",
    "outputId": "c1681d4c-3b99-429c-fa3f-6b8ef879e0de"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#!pip install plotly\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0],X[:,1],Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e06070",
   "metadata": {},
   "source": [
    "### Linear model (simple)\n",
    "\n",
    "Sachant que notre matrice d’input était\n",
    "{(1,2,3},(1,2,3)} , les deux colonnes sont donc des combinaisons linéaire l’une\n",
    "de l’autre (C1 = C2 ; L2 = 2L1...) de ce fait lors de l'exécution plus avant de la\n",
    "librairie il nous est impossible de réaliser l’inverse cette matrice. Pour\n",
    "contrer ce problème nous avons découvert qu’il était possible de dupliquer\n",
    "une des lignes du dataset pour briser cette restriction sans créer de nouvelle\n",
    "datas.\n",
    "Une autre possibilité proposée mais moins sur car elle ajoutait de nouvelles\n",
    "données au dataset. Les nouveaux points étaient des jumeaux des points\n",
    "déjà existant avec des coordonnées décaler sur le repère à l’échelle de\n",
    "0.00001 pour minimiser l’impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ed0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b6f5c",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "    \n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451ccc5d",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c734f16",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1] \n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "    \n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0] for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0]  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654a8d",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 3\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, num_classes) for coord in plot_input]]\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(plot_input))], \"x0\": plot_input[:, 0], \"x1\": plot_input[:, 1], \"z_aft\":plot_output_value})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7187e0c",
   "metadata": {
    "id": "kO361TllBqbm"
   },
   "source": [
    "### Linear Tricky 3D :\n",
    "        Linear Model    : OK\n",
    "        MLP (2, 1)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dd0bb",
   "metadata": {
    "id": "nR_i7qLxBqbm"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1, 1],\n",
    "      [2, 2],\n",
    "      [3, 3]\n",
    "])\n",
    "Y = np.array([\n",
    "      1,\n",
    "      2,\n",
    "      3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c9eb6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "dHriVYrKBqbo",
    "outputId": "681a33c5-8ad5-427a-beea-eaf2a4e268ac"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0],X[:,1],Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f3caf",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [1, 1])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654f900",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0]) # 2\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "    \n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "#print(df.head())\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318acec",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               epochs=100000)\n",
    "\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [1, 1])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9501d0",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "    \n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0] for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0]  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b1a19",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078adab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 3\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, num_classes) for coord in plot_input]]\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(plot_input))], \"x0\": plot_input[:, 0], \"x1\": plot_input[:, 1], \"z_aft\":plot_output_value})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb662bd",
   "metadata": {
    "id": "H_h0_vtCBEzk"
   },
   "source": [
    "### Non Linear Simple 3D :\n",
    "        Linear Model       : KO\n",
    "        MLP (2, 2, 1)      : OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb42013",
   "metadata": {
    "id": "ij70I1H9BEzk"
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "      [1, 0],\n",
    "      [0, 1],\n",
    "      [1, 1],\n",
    "      [0, 0],\n",
    "])\n",
    "Y = np.array([\n",
    "      2,\n",
    "      1,\n",
    "      -2,\n",
    "      -1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075efbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "N3VDOby8BEzn",
    "outputId": "ef903fb3-08ed-4afd-f1e0-bcaed828b118"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(X[:,0],X[:,1],Y)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604005b8",
   "metadata": {},
   "source": [
    "### Linear model (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df13190",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "\n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_before = predict_linear_model_regression(model, input_dim, [1, 0])\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "test_after = predict_linear_model_regression(model, input_dim, [1, 0])\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67df0",
   "metadata": {},
   "source": [
    "### Linear model (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(X[0])\n",
    "\n",
    "model = create_linear_model(input_dim)\n",
    "    \n",
    "flattened_dataset_inputs = np.array(X).flatten()\n",
    "\n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_linear_regression_model(model, input_dim, flattened_dataset_inputs, Y)\n",
    "\n",
    "predicted_outputs = np.array([predict_linear_model_regression(model, input_dim, x)  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_linear_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447813c7",
   "metadata": {},
   "source": [
    "### MLP (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "\n",
    "test_before = predict_mlp_model_regression(model, [1, 0])[0]\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               epochs=100000)\n",
    "\n",
    "\n",
    "test_after = predict_mlp_model_regression(model, [1, 0])[0]\n",
    "\n",
    "print(\"before:\", test_before)\n",
    "print(\"after:\", test_after)\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333923d",
   "metadata": {},
   "source": [
    "### MLP (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799d424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [len(X[0]), len(X[0]), 1]\n",
    "\n",
    "model, _ = create_mlp_model(input_dim)\n",
    "    \n",
    "test_dataset_inputs = np.array([[i, j] for i in np.arange(0, 6, 0.1) for j in np.arange(0, 6, 0.1)])\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0] for x in test_dataset_inputs])\n",
    "\n",
    "df = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_prev\":predicted_outputs})\n",
    "\n",
    "old = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_prev\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old)\n",
    "d = pd.concat([df, df2], ignore_index = True)\n",
    "d.reset_index()\n",
    "\n",
    "fig = px.scatter_3d(d, x=\"x0\", y=\"x1\", z=\"z_prev\", color=\"cat\", size=[10 for _ in range(len(d))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "train_regression_stochastic_gradient_backpropagation_mlp_model(model, \n",
    "                                                               X, \n",
    "                                                               Y,\n",
    "                                                               alpha=0.01,\n",
    "                                                              epochs=100000)\n",
    "\n",
    "\n",
    "predicted_outputs = np.array([predict_mlp_model_regression(model, x)[0]  for x in test_dataset_inputs])\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(test_dataset_inputs))], \"x0\": test_dataset_inputs[:, 0], \"x1\": test_dataset_inputs[:, 1], \"z_aft\":predicted_outputs})\n",
    "\n",
    "old2 = {\"cat\": [\"B\", \"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")\n",
    "\n",
    "destroy_mlp_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29756783",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10feb64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "k = 4\n",
    "input_dim = 2\n",
    "expected_output = Y\n",
    "modif_input = X\n",
    "model = create_rbfn_model(input_dim, num_classes, k)\n",
    "train_rbfn_model(model, modif_input, expected_output, True)\n",
    "\n",
    "plot_input = np.array([[i, j] for i in np.arange(0, 2, 0.1) for j in np.arange(0, 2, 0.1)])\n",
    "plot_output_value = [predict[0] for predict in [predict_rbfn(model, coord, num_classes) for coord in plot_input]]\n",
    "\n",
    "df_aft = pd.DataFrame({\"cat\": [\"A\" for _ in range(len(plot_input))], \"x0\": plot_input[:, 0], \"x1\": plot_input[:, 1], \"z_aft\":plot_output_value})\n",
    "\n",
    "#old2 = {\"cat\": [\"B\", \"B\", \"B\"], \"x0\": X[:,0], \"x1\": X[:,1], \"z_aft\":Y}\n",
    "\n",
    "#df2 = pd.DataFrame(old2)\n",
    "d_aft = pd.concat([df_aft, df2], ignore_index = True)\n",
    "d_aft.reset_index()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(d_aft, x=\"x0\", y=\"x1\", z=\"z_aft\", color=\"cat\", size=[10 for _ in range(len(d_aft))])\n",
    "fig.show(\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
